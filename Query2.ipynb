{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Προχωρημένα Θέματα Βάσεων Δεδομένων\n",
    "\n",
    "**Ονοματεπώνυμο:** Κωνσταντίνος Διβριώτης\n",
    "\n",
    "**ΑΜ:** 03114140\n",
    "\n",
    "## Query 2: \n",
    "\n",
    "Να βρεθούν, για κάθε έτος, τα 3 Αστυνομικά Τμήματα με το υψηλότερο ποσοστό κλεισμένων (περατωμένων) υποθέσεων. \n",
    "\n",
    "Να τυπωθούν το έτος, τα ονόματα (τοποθεσίες) των τμημάτων, τα ποσοστά τους καθώς και οι αριθμοί του ranking τους στην ετήσια κατάταξη. \n",
    "\n",
    "Τα αποτελέσματα να δοθούν σε σειρά αύξουσα ως προς το έτος και το ranking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "2uaG6GoZthpT",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>1038</td><td>application_1732639283265_1005</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-36.eu-central-1.compute.internal:20888/proxy/application_1732639283265_1005/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-94.eu-central-1.compute.internal:8042/node/containerlogs/container_1732639283265_1005_01_000001/livy\">Link</a></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import time\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"PoliceStationsAnalysis\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DATA_BUCKET = \"s3://initial-notebook-data-bucket-dblab-905418150721\"\n",
    "GROUP_BUCKET = \"s3://groups-bucket-dblab-905418150721/group15\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.types import StructField, StructType, IntegerType, StringType, DoubleType\n",
    "\n",
    "# Ορισμός του schema των dataset\n",
    "crimes_schema = StructType([\n",
    "    StructField(\"DR_NO\", StringType()),\n",
    "    StructField(\"Date Rptd\", StringType()),\n",
    "    StructField(\"DATE OCC\", StringType()),\n",
    "    StructField(\"TIME OCC\", StringType()),\n",
    "    StructField(\"AREA\", IntegerType()),\n",
    "    StructField(\"AREA NAME\", StringType()),\n",
    "    StructField(\"Rpt Dist No\", StringType()),\n",
    "    StructField(\"Part 1-2\", IntegerType()),\n",
    "    StructField(\"Crm Cd\", IntegerType()),\n",
    "    StructField(\"Crm Cd Desc\", StringType()),\n",
    "    StructField(\"Mocodes\", StringType()),\n",
    "    StructField(\"Vict Age\", IntegerType()),\n",
    "    StructField(\"Vict Sex\", StringType()),\n",
    "    StructField(\"Vict Descent\", StringType()),\n",
    "    StructField(\"Premis Cd\", StringType()),\n",
    "    StructField(\"Premis Desc\", StringType()),\n",
    "    StructField(\"Weapon Used Cd\", IntegerType()),\n",
    "    StructField(\"Weapon Desc\", StringType()),\n",
    "    StructField(\"Status\", StringType()),\n",
    "    StructField(\"Status Desc\", StringType()),\n",
    "    StructField(\"Crm Cd 1\", IntegerType()),\n",
    "    StructField(\"Crm Cd 2\", IntegerType()),\n",
    "    StructField(\"Crm Cd 3\", IntegerType()),\n",
    "    StructField(\"Crm Cd 4\", IntegerType()),\n",
    "    StructField(\"LOCATION\", StringType()),\n",
    "    StructField(\"Cross Street\", StringType()),\n",
    "    StructField(\"LAT\", DoubleType()),\n",
    "    StructField(\"LON\", DoubleType())\n",
    "])\n",
    "\n",
    "police_stations_schema = StructType([\n",
    "    StructField(\"X\", DoubleType()),\n",
    "    StructField(\"Y\", DoubleType()),\n",
    "    StructField(\"FID\", IntegerType()),\n",
    "    StructField(\"DIVISION\", StringType()),\n",
    "    StructField(\"LOCATION\", StringType()),\n",
    "    StructField(\"PREC\", IntegerType())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Ερώτημα α"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Υλοποίηση με DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------------+------------------+---+\n",
      "|year|       precinct|  closed_case_rate|  #|\n",
      "+----+---------------+------------------+---+\n",
      "|2010|        RAMPART| 32.84713448949121|  1|\n",
      "|2010|        OLYMPIC|31.515289821999087|  2|\n",
      "|2010|         HARBOR| 29.36028339237341|  3|\n",
      "|2011|        OLYMPIC|  35.0400600901352|  1|\n",
      "|2011|        RAMPART|32.496447181430604|  2|\n",
      "|2011|         HARBOR|28.513362463164313|  3|\n",
      "|2012|        OLYMPIC| 34.29708533302119|  1|\n",
      "|2012|        RAMPART| 32.46000463714352|  2|\n",
      "|2012|         HARBOR| 29.50958584895668|  3|\n",
      "|2013|        OLYMPIC| 33.58217940999398|  1|\n",
      "|2013|        RAMPART|  32.1060382916053|  2|\n",
      "|2013|         HARBOR|29.727164887307236|  3|\n",
      "|2014|       VAN NUYS|  32.0215235281705|  1|\n",
      "|2014|    WEST VALLEY| 31.49754809505847|  2|\n",
      "|2014|        MISSION| 31.22493985565357|  3|\n",
      "|2015|       VAN NUYS|32.265140677157845|  1|\n",
      "|2015|        MISSION|30.463762673676303|  2|\n",
      "|2015|       FOOTHILL|30.353001803658852|  3|\n",
      "|2016|       VAN NUYS|32.194518462124094|  1|\n",
      "|2016|    WEST VALLEY| 31.40146437042384|  2|\n",
      "|2016|       FOOTHILL| 29.90864722813165|  3|\n",
      "|2017|       VAN NUYS|  32.0554272517321|  1|\n",
      "|2017|        MISSION|31.055387158996968|  2|\n",
      "|2017|       FOOTHILL|30.469700657094183|  3|\n",
      "|2018|       FOOTHILL|30.731346958877126|  1|\n",
      "|2018|        MISSION|30.727023319615913|  2|\n",
      "|2018|       VAN NUYS| 28.90520694259012|  3|\n",
      "|2019|        MISSION|30.727411112319235|  1|\n",
      "|2019|    WEST VALLEY| 30.57974335472044|  2|\n",
      "|2019|NORTH HOLLYWOOD|29.238086691196266|  3|\n",
      "|2020|    WEST VALLEY|30.771131982204647|  1|\n",
      "|2020|        MISSION|30.149746492158943|  2|\n",
      "|2020|         HARBOR|29.693486590038315|  3|\n",
      "|2021|        MISSION|30.318115590092276|  1|\n",
      "|2021|    WEST VALLEY|28.971087440009363|  2|\n",
      "|2021|       FOOTHILL|27.993757094211123|  3|\n",
      "|2022|    WEST VALLEY|26.536367172306495|  1|\n",
      "|2022|         HARBOR|26.337538060026098|  2|\n",
      "|2022|        TOPANGA|26.234013317831096|  3|\n",
      "|2023|       FOOTHILL|26.760760201229736|  1|\n",
      "|2023|        TOPANGA| 26.53802261645399|  2|\n",
      "|2023|        MISSION| 25.66273112051682|  3|\n",
      "|2024|NORTH HOLLYWOOD|19.598528961078763|  1|\n",
      "|2024|       FOOTHILL|18.620882188721385|  2|\n",
      "|2024|    77TH STREET|17.586318167150694|  3|\n",
      "+----+---------------+------------------+---+"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from pyspark.sql.functions import to_timestamp, col, year, rank, count\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Διαβάζουμε τα 2 datasets (2010-2019 και 2020-σήμερα) και τα συνενώνουμε σε 1\n",
    "crime_data_2010_2019 = spark.read.csv(f\"{DATA_BUCKET}/CrimeData/Crime_Data_from_2010_to_2019_20241101.csv\", header=True, schema=crimes_schema)\n",
    "crime_data_2020_present = spark.read.csv(f\"{DATA_BUCKET}/CrimeData/Crime_Data_from_2020_to_Present_20241101.csv\", header=True, schema=crimes_schema)\n",
    "crime_data = crime_data_2010_2019.union(crime_data_2020_present)\n",
    "\n",
    "# Κάνουμε parse τα datetime strings του CSV ως timestamps και\n",
    "# δημιουργούμε νέα στήλη για το έτος στο οποίο συνέβη κάθε έγκλημα\n",
    "datetime_format = \"MM/dd/yyyy hh:mm:ss a\"\n",
    "crime_data = crime_data \\\n",
    "                .withColumn(\"Date Rptd\", to_timestamp(\"Date Rptd\", datetime_format)) \\\n",
    "                .withColumn(\"DATE OCC\", to_timestamp(\"DATE OCC\", datetime_format)) \\\n",
    "                .withColumn(\"year\", year(col(\"DATE OCC\"))) \\\n",
    "                .filter(col(\"Status\").isNotNull())\n",
    "\n",
    "# Βρίσκουμε το σύνολο των περιστατικών καθώς και το σύνολο\n",
    "# των κλεισμένων υποθέσεων ανά τμήμα και ανά έτος\n",
    "total_cases = crime_data.groupBy(\"AREA\", \"year\") \\\n",
    "                .count() \\\n",
    "                .withColumnRenamed(\"count\", \"Total Cases\")\n",
    "\n",
    "# Υποθέτουμε ότι οι υποθέσεις που έχουν κλείσει είναι όσες δεν έχουν\n",
    "# Status Description UNK (Unknown) ή Invest Cont (Investigation Continuing).\n",
    "# Δηλαδή, όσες έχουν status AA/AO (Adult Arrest/Other) ή\n",
    "# JA/JO (Juvenile Arrest/Other).\n",
    "closed_cases = crime_data \\\n",
    "                .filter(~ col(\"Status Desc\").isin(\"UNK\", \"Invest Cont\")) \\\n",
    "                .groupBy(\"AREA\", \"year\") \\\n",
    "                .agg(count(\"*\").alias(\"Closed Cases\"))\n",
    "\n",
    "# Υπολογίζουμε το ποσοστό των κλεισμένων υποθέσεων ανά τμήμα\n",
    "closed_cases = closed_cases.join(total_cases, on=[\"AREA\", \"year\"]) \\\n",
    "                        .withColumn(\"closed_case_rate\", 100 * col(\"Closed Cases\") / col(\"Total Cases\"))\n",
    "\n",
    "# Διαβάζουμε το dataset των Αστυνομικών Τμημάτων\n",
    "police_stations = spark.read.csv(f\"{DATA_BUCKET}/LA_Police_Stations.csv\",\n",
    "                                 header=True, \\\n",
    "                                 schema=police_stations_schema)\n",
    "\n",
    "# Ενώνουμε τους 2 πίνακες προκειμένου να έχουμε το όνομα του τμήματος σε κάθε γραμμή\n",
    "closed_cases = closed_cases.join(police_stations,\n",
    "                                 closed_cases[\"AREA\"] == police_stations[\"PREC\"])\n",
    "\n",
    "# Υπολογίζουμε το rank του κάθε αστυνομικού τμήματος με βάση το\n",
    "# closed_case_rate ανά έτος, και κρατάμε μόνο τα πρώτα 3 rank ανά έτος\n",
    "window_spec = Window.partitionBy(\"year\").orderBy(col(\"closed_case_rate\").desc())\n",
    "ranked_cases = closed_cases.withColumn(\"#\", rank().over(window_spec)) \\\n",
    "                            .filter(col(\"#\") <= 3) \\\n",
    "                            .orderBy(\"year\", \"#\")\n",
    "\n",
    "ranked_cases.withColumnRenamed(\"DIVISION\", \"precinct\") \\\n",
    "            .select(\"year\", \"precinct\", \"closed_case_rate\", \"#\") \\\n",
    "            .show(3*(2024-2010+1))\n",
    "\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 6.59 seconds"
     ]
    }
   ],
   "source": [
    "elapsed_time = end_time - start_time\n",
    "print(f\"Time taken: {elapsed_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Υλοποίηση με SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------------+-----------------+---+\n",
      "|year|       precinct| closed_case_rate|  #|\n",
      "+----+---------------+-----------------+---+\n",
      "|2010|        RAMPART|32.84713448949121|  1|\n",
      "|2010|        OLYMPIC|31.51528982199909|  2|\n",
      "|2010|         HARBOR|29.36028339237341|  3|\n",
      "|2011|        OLYMPIC|35.04006009013520|  1|\n",
      "|2011|        RAMPART|32.49644718143060|  2|\n",
      "|2011|         HARBOR|28.51336246316431|  3|\n",
      "|2012|        OLYMPIC|34.29708533302119|  1|\n",
      "|2012|        RAMPART|32.46000463714352|  2|\n",
      "|2012|         HARBOR|29.50958584895668|  3|\n",
      "|2013|        OLYMPIC|33.58217940999398|  1|\n",
      "|2013|        RAMPART|32.10603829160530|  2|\n",
      "|2013|         HARBOR|29.72363895148855|  3|\n",
      "|2014|       VAN NUYS|32.02152352817050|  1|\n",
      "|2014|    WEST VALLEY|31.49754809505847|  2|\n",
      "|2014|        MISSION|31.22493985565357|  3|\n",
      "|2015|       VAN NUYS|32.26514067715784|  1|\n",
      "|2015|        MISSION|30.46376267367630|  2|\n",
      "|2015|       FOOTHILL|30.35300180365885|  3|\n",
      "|2016|       VAN NUYS|32.19451846212410|  1|\n",
      "|2016|    WEST VALLEY|31.40146437042384|  2|\n",
      "|2016|       FOOTHILL|29.90864722813165|  3|\n",
      "|2017|       VAN NUYS|32.05542725173210|  1|\n",
      "|2017|        MISSION|31.05538715899697|  2|\n",
      "|2017|       FOOTHILL|30.46970065709418|  3|\n",
      "|2018|       FOOTHILL|30.73134695887712|  1|\n",
      "|2018|        MISSION|30.72702331961591|  2|\n",
      "|2018|       VAN NUYS|28.90520694259012|  3|\n",
      "|2019|        MISSION|30.72741111231923|  1|\n",
      "|2019|    WEST VALLEY|30.57974335472044|  2|\n",
      "|2019|NORTH HOLLYWOOD|29.23808669119627|  3|\n",
      "|2020|    WEST VALLEY|30.77113198220465|  1|\n",
      "|2020|        MISSION|30.14974649215894|  2|\n",
      "|2020|         HARBOR|29.69348659003831|  3|\n",
      "|2021|        MISSION|30.31811559009228|  1|\n",
      "|2021|    WEST VALLEY|28.97108744000936|  2|\n",
      "|2021|       FOOTHILL|27.99375709421112|  3|\n",
      "|2022|    WEST VALLEY|26.53636717230650|  1|\n",
      "|2022|         HARBOR|26.33753806002610|  2|\n",
      "|2022|        TOPANGA|26.23401331783110|  3|\n",
      "|2023|       FOOTHILL|26.76076020122974|  1|\n",
      "|2023|        TOPANGA|26.53802261645399|  2|\n",
      "|2023|        MISSION|25.66273112051682|  3|\n",
      "|2024|NORTH HOLLYWOOD|19.59852896107876|  1|\n",
      "|2024|       FOOTHILL|18.62088218872138|  2|\n",
      "|2024|    77TH STREET|17.58631816715069|  3|\n",
      "+----+---------------+-----------------+---+"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from pyspark.sql.functions import to_timestamp\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Διαβάζουμε τα 2 datasets (2010-2019 και 2020-σήμερα) και τα συνενώνουμε σε 1\n",
    "crime_data_2010_2019 = spark.read.csv(f\"{DATA_BUCKET}/CrimeData/Crime_Data_from_2010_to_2019_20241101.csv\", header=True, schema=crimes_schema)\n",
    "crime_data_2020_present = spark.read.csv(f\"{DATA_BUCKET}/CrimeData/Crime_Data_from_2020_to_Present_20241101.csv\", header=True, schema=crimes_schema)\n",
    "crime_data = crime_data_2010_2019.union(crime_data_2020_present)\n",
    "\n",
    "# Κάνουμε parse τα datetime strings του CSV ως timestamps και\n",
    "# δημιουργούμε νέα στήλη για το έτος στο οποίο συνέβη κάθε έγκλημα\n",
    "datetime_format = \"MM/dd/yyyy hh:mm:ss a\"\n",
    "crime_data = crime_data \\\n",
    "                .withColumn(\"Date Rptd\", to_timestamp(\"Date Rptd\", datetime_format)) \\\n",
    "                .withColumn(\"DATE OCC\", to_timestamp(\"DATE OCC\", datetime_format))\n",
    "\n",
    "# Χρήση σαν SQL table\n",
    "crime_data.createOrReplaceTempView(\"crime_data\")\n",
    "\n",
    "# crime_data.groupBy(\"Status\", \"Status Desc\").count().show()\n",
    "\n",
    "# Βρίσκουμε το σύνολο των περιστατικών καθώς και το σύνολο\n",
    "# των κλεισμένων υποθέσεων ανά τμήμα και ανά έτος\n",
    "query = \"SELECT `AREA`, YEAR(`DATE OCC`) AS year, COUNT(*) AS `count` \\\n",
    "            FROM crime_data as cd \\\n",
    "            GROUP BY `AREA`, YEAR(`DATE OCC`)\"\n",
    "\n",
    "total_cases = spark.sql(query)\n",
    "total_cases.createOrReplaceTempView(\"total_cases\")\n",
    "\n",
    "# Υποθέτουμε ότι οι υποθέσεις που έχουν κλείσει είναι όσες είναι\n",
    "# σε status AA/AO (Adult Arrest/Other) ή JA/JO (Juvenile Arrest/Other).\n",
    "# Εναλλακτικά, θα μπορούσαμε να υποθέσουμε ότι έχουν κλείσει όσες ΔΕΝ\n",
    "# είναι σε status IC (Investigation Continuing) - αλλά προτιμούμε να\n",
    "# μην συμπεριλάβουμε τα status CC, 19, 13, TH για τα οποία η περιγραφή\n",
    "# (Status Desc) έχει τιμή UNK (Unknown)\n",
    "query = \"SELECT `AREA`, YEAR(`DATE OCC`) AS year, COUNT(*) AS `count` \\\n",
    "            FROM crime_data as cd \\\n",
    "            WHERE `Status Desc` NOT IN ('UNK', 'Invest Cont') \\\n",
    "            GROUP BY `AREA`, YEAR(`DATE OCC`)\"\n",
    "\n",
    "closed_cases = spark.sql(query)\n",
    "closed_cases.createOrReplaceTempView(\"closed_cases\")\n",
    "\n",
    "# Υπολογίζουμε το ποσοστό των κλεισμένων υποθέσεων ανά τμήμα\n",
    "query = \"SELECT cc.AREA AS `AREA`, cc.year AS `year`, (100.0 * cc.count / tc.count) AS `closed_case_rate` \\\n",
    "            FROM closed_cases AS cc \\\n",
    "            JOIN total_cases AS tc \\\n",
    "            ON cc.AREA = tc.AREA AND cc.year = tc.year\"\n",
    "\n",
    "closed_cases = spark.sql(query)\n",
    "closed_cases.createOrReplaceTempView(\"closed_cases\")\n",
    "\n",
    "# Διαβάζουμε το dataset των Αστυνομικών Τμημάτων\n",
    "police_stations = spark.read.csv(f\"{DATA_BUCKET}/LA_Police_Stations.csv\",\n",
    "                                 header=True, \\\n",
    "                                 schema=police_stations_schema)\n",
    "police_stations.createOrReplaceTempView(\"police_stations\")\n",
    "\n",
    "# Ενώνουμε τους 2 πίνακες προκειμένου να έχουμε το όνομα του τμήματος σε κάθε γραμμή\n",
    "query = \"SELECT `year`, `DIVISION` AS `precinct`, `closed_case_rate` \\\n",
    "            FROM closed_cases AS cc \\\n",
    "            JOIN police_stations AS ps \\\n",
    "            ON cc.AREA = ps.PREC\"\n",
    "\n",
    "closed_cases = spark.sql(query)\n",
    "closed_cases.createOrReplaceTempView(\"closed_cases\")\n",
    "\n",
    "# Υπολογίζουμε το rank του κάθε αστυνομικού τμήματος με βάση το\n",
    "# closed_case_rate ανά έτος, και κρατάμε μόνο τα πρώτα 3 rank ανά έτος\n",
    "query = \"SELECT * FROM ( \\\n",
    "            SELECT `year`, `precinct`, `closed_case_rate`, RANK() OVER (PARTITION BY `year` ORDER BY `closed_case_rate` DESC) as `#` \\\n",
    "            FROM closed_cases \\\n",
    "            ORDER BY `year`, `#` \\\n",
    "            ) \\\n",
    "            WHERE `#` <= 3\"\n",
    "\n",
    "ranked_cases = spark.sql(query)\n",
    "ranked_cases.show(3*(2024-2010+1))\n",
    "\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 5.57 seconds"
     ]
    }
   ],
   "source": [
    "elapsed_time = end_time - start_time\n",
    "print(f\"Time taken: {elapsed_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Συμπεράσματα\n",
    "\n",
    "Οι δύο υλοποίησεις με χρήση του **DataFrame API** και του **SQL API** ήταν παρόμοιες όσον αφορά τον χρόνο εκτέλεσης, με χρόνους 6.59 και 5.57 δευτερόλεπτα αντίστοιχα. \n",
    "\n",
    "Φυσικά αναμέναμε ότι οι διαφορές θα ήταν ελάχιστες, καθώς και τα 2 APIs βασίζονται στον βελτιστοποιητή **Catalyst** του **Spark**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ερώτημα β"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Μετατροπή του κυρίως Dataset σε parquet file format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "crime_data_2010_2019 = spark.read.csv(f\"{DATA_BUCKET}/CrimeData/Crime_Data_from_2010_to_2019_20241101.csv\", header=True, schema=crimes_schema)\n",
    "crime_data_2020_present = spark.read.csv(f\"{DATA_BUCKET}/CrimeData/Crime_Data_from_2020_to_Present_20241101.csv\", header=True, schema=crimes_schema)\n",
    "crime_data = crime_data_2010_2019.union(crime_data_2020_present)\n",
    "\n",
    "crime_data.write.mode(\"overwrite\").parquet(f\"{GROUP_BUCKET}/Crime_Data_from_2010_to_Present\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Υλοποίηση με DataFrame και αρχείο parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------------+------------------+---+\n",
      "|year|       precinct|  closed_case_rate|  #|\n",
      "+----+---------------+------------------+---+\n",
      "|2010|        RAMPART| 32.84713448949121|  1|\n",
      "|2010|        OLYMPIC|31.515289821999087|  2|\n",
      "|2010|         HARBOR| 29.36028339237341|  3|\n",
      "|2011|        OLYMPIC|  35.0400600901352|  1|\n",
      "|2011|        RAMPART|32.496447181430604|  2|\n",
      "|2011|         HARBOR|28.513362463164313|  3|\n",
      "|2012|        OLYMPIC| 34.29708533302119|  1|\n",
      "|2012|        RAMPART| 32.46000463714352|  2|\n",
      "|2012|         HARBOR| 29.50958584895668|  3|\n",
      "|2013|        OLYMPIC| 33.58217940999398|  1|\n",
      "|2013|        RAMPART|  32.1060382916053|  2|\n",
      "|2013|         HARBOR|29.727164887307236|  3|\n",
      "|2014|       VAN NUYS|  32.0215235281705|  1|\n",
      "|2014|    WEST VALLEY| 31.49754809505847|  2|\n",
      "|2014|        MISSION| 31.22493985565357|  3|\n",
      "|2015|       VAN NUYS|32.265140677157845|  1|\n",
      "|2015|        MISSION|30.463762673676303|  2|\n",
      "|2015|       FOOTHILL|30.353001803658852|  3|\n",
      "|2016|       VAN NUYS|32.194518462124094|  1|\n",
      "|2016|    WEST VALLEY| 31.40146437042384|  2|\n",
      "|2016|       FOOTHILL| 29.90864722813165|  3|\n",
      "|2017|       VAN NUYS|  32.0554272517321|  1|\n",
      "|2017|        MISSION|31.055387158996968|  2|\n",
      "|2017|       FOOTHILL|30.469700657094183|  3|\n",
      "|2018|       FOOTHILL|30.731346958877126|  1|\n",
      "|2018|        MISSION|30.727023319615913|  2|\n",
      "|2018|       VAN NUYS| 28.90520694259012|  3|\n",
      "|2019|        MISSION|30.727411112319235|  1|\n",
      "|2019|    WEST VALLEY| 30.57974335472044|  2|\n",
      "|2019|NORTH HOLLYWOOD|29.238086691196266|  3|\n",
      "|2020|    WEST VALLEY|30.771131982204647|  1|\n",
      "|2020|        MISSION|30.149746492158943|  2|\n",
      "|2020|         HARBOR|29.693486590038315|  3|\n",
      "|2021|        MISSION|30.318115590092276|  1|\n",
      "|2021|    WEST VALLEY|28.971087440009363|  2|\n",
      "|2021|       FOOTHILL|27.993757094211123|  3|\n",
      "|2022|    WEST VALLEY|26.536367172306495|  1|\n",
      "|2022|         HARBOR|26.337538060026098|  2|\n",
      "|2022|        TOPANGA|26.234013317831096|  3|\n",
      "|2023|       FOOTHILL|26.760760201229736|  1|\n",
      "|2023|        TOPANGA| 26.53802261645399|  2|\n",
      "|2023|        MISSION| 25.66273112051682|  3|\n",
      "|2024|NORTH HOLLYWOOD|19.598528961078763|  1|\n",
      "|2024|       FOOTHILL|18.620882188721385|  2|\n",
      "|2024|    77TH STREET|17.586318167150694|  3|\n",
      "+----+---------------+------------------+---+"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "crime_data_parquet = spark.read.parquet(f\"{GROUP_BUCKET}/Crime_Data_from_2010_to_Present\")\n",
    "\n",
    "# Κάνουμε parse τα datetime strings του CSV ως timestamps και\n",
    "# δημιουργούμε νέα στήλη για το έτος στο οποίο συνέβη κάθε έγκλημα\n",
    "datetime_format = \"MM/dd/yyyy hh:mm:ss a\"\n",
    "crime_data_parquet = crime_data_parquet \\\n",
    "                .withColumn(\"Date Rptd\", to_timestamp(\"Date Rptd\", datetime_format)) \\\n",
    "                .withColumn(\"DATE OCC\", to_timestamp(\"DATE OCC\", datetime_format)) \\\n",
    "                .withColumn(\"year\", year(col(\"DATE OCC\"))) \\\n",
    "                .filter(col(\"Status\").isNotNull())\n",
    "\n",
    "# crime_data.groupBy(\"Status\", \"Status Desc\").count().show()\n",
    "\n",
    "# Βρίσκουμε το σύνολο των περιστατικών καθώς και το σύνολο\n",
    "# των κλεισμένων υποθέσεων ανά τμήμα και ανά έτος\n",
    "total_cases = crime_data_parquet.groupBy(\"AREA\", \"year\") \\\n",
    "                .count() \\\n",
    "                .withColumnRenamed(\"count\", \"Total Cases\")\n",
    "\n",
    "# Υποθέτουμε ότι οι υποθέσεις που έχουν κλείσει είναι όσες είναι\n",
    "# σε status AA/AO (Adult Arrest/Other) ή JA/JO (Juvenile Arrest/Other).\n",
    "# Εναλλακτικά, θα μπορούσαμε να υποθέσουμε ότι έχουν κλείσει όσες ΔΕΝ\n",
    "# είναι σε status IC (Investigation Continuing) - αλλά προτιμούμε να\n",
    "# μην συμπεριλάβουμε τα status CC, 19, 13, TH για τα οποία η περιγραφή\n",
    "# (Status Desc) έχει τιμή UNK (Unknown)\n",
    "closed_cases = crime_data_parquet \\\n",
    "                .filter(~ col(\"Status Desc\").isin(\"UNK\", \"Invest Cont\")) \\\n",
    "                .groupBy(\"AREA\", \"year\") \\\n",
    "                .agg(count(\"*\").alias(\"Closed Cases\"))\n",
    "\n",
    "# Υπολογίζουμε το ποσοστό των κλεισμένων υποθέσεων ανά τμήμα\n",
    "closed_cases = closed_cases.join(total_cases, on=[\"AREA\", \"year\"]) \\\n",
    "                        .withColumn(\"closed_case_rate\", 100 * col(\"Closed Cases\") / col(\"Total Cases\"))\n",
    "\n",
    "# Διαβάζουμε το dataset των Αστυνομικών Τμημάτων\n",
    "police_stations = spark.read.csv(f\"{DATA_BUCKET}/LA_Police_Stations.csv\",\n",
    "                                 header=True, \\\n",
    "                                 schema=police_stations_schema)\n",
    "\n",
    "# Ενώνουμε τους 2 πίνακες προκειμένου να έχουμε το όνομα του τμήματος σε κάθε γραμμή\n",
    "closed_cases = closed_cases.join(police_stations,\n",
    "                                 closed_cases[\"AREA\"] == police_stations[\"PREC\"])\n",
    "\n",
    "# Υπολογίζουμε το rank του κάθε αστυνομικού τμήματος με βάση το\n",
    "# closed_case_rate ανά έτος, και κρατάμε μόνο τα πρώτα 3 rank ανά έτος\n",
    "window_spec = Window.partitionBy(\"year\").orderBy(col(\"closed_case_rate\").desc())\n",
    "ranked_cases = closed_cases.withColumn(\"#\", rank().over(window_spec)) \\\n",
    "                            .filter(col(\"#\") <= 3) \\\n",
    "                            .orderBy(\"year\", \"#\")\n",
    "\n",
    "ranked_cases.withColumnRenamed(\"DIVISION\", \"precinct\") \\\n",
    "            .select(\"year\", \"precinct\", \"closed_case_rate\", \"#\") \\\n",
    "            .show(3*(2024-2010+1))\n",
    "\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 3.40 seconds"
     ]
    }
   ],
   "source": [
    "elapsed_time = end_time - start_time\n",
    "print(f\"Time taken: {elapsed_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Συμπεράσματα\n",
    "\n",
    "Χρησιμοποιώντας το αρχείο *parquet* που εξάγαμε έναντι των 2 αρχικών CSV του κυρίως dataset παρατηρούμε μία βελτίωση από τα 6.59 στα 3.40 δευτερόλεπτα.\n",
    "\n",
    "Αυτό οφείλεται αφενός στο ότι το αρχείο parquet πετυχαίνει πολύ καλή συμπίεση, αφού το εξαγόμενο αρχείο έχει μέγεθος 127 MB έναντι των 752 MB των 2 αρχικών CSV.\n",
    "\n",
    "Η σημαντικότερη διαφορά όμως έχει να κάνει με τον τρόπο που είναι αποθηκευμένα τα δεδομένα, τα οποία είναι σε **Columnar** μορφή αντί για **row-based** όπως το CSV. Αυτό βοηθάει στη γρηγορότερη ανάγνωση και επεξεργασία των δεδομένων.\n",
    "\n",
    "Τέλος, το αρχείο parquet υποστηρίζει **predicate pushdown**, το οποίο δίνει τη δυνατότητα να φιλτραριστούν τα δεδομένα πριν να διαβαστούν στη μνήμη και συνεπώς πετυχαίνουμε καλύτερη βελτιστοποίηση."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Sparkmagic (PySpark)",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  },
  "name": "SparkLab - Introduction to RDDs and DataFrames"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
