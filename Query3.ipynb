{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Προχωρημένα Θέματα Βάσεων Δεδομένων\n",
    "\n",
    "**Ονοματεπώνυμο:** Κωνσταντίνος Διβριώτης\n",
    "\n",
    "**ΑΜ:** 03114140\n",
    "\n",
    "## Query 3: \n",
    "\n",
    "Χρησιμοποιώντας ως αναφορά τα δεδομένα της απογραφής 2010 για τον πληθυσμό και εκείνα της απογραφής του 2015 για το εισόδημα ανα νοικοκυριό, να υπολογίσετε για κάθε περιοχή του Los Angeles τα παρακάτω:\n",
    "- Το μέσο ετήσιο εισόδημα ανά άτομο\n",
    "- Την αναλογία συνολικού αριθμού εγκλημάτων ανά άτομο"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "2uaG6GoZthpT",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>1370</td><td>application_1732639283265_1332</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-36.eu-central-1.compute.internal:20888/proxy/application_1732639283265_1332/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-233.eu-central-1.compute.internal:8042/node/containerlogs/container_1732639283265_1332_01_000001/livy\">Link</a></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from sedona.spark import *\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"CensusDataAnalysis\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sedona = SedonaContext.create(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DATA_BUCKET = \"s3://initial-notebook-data-bucket-dblab-905418150721\"\n",
    "GROUP_BUCKET = \"s3://groups-bucket-dblab-905418150721/group15\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Διάβασμα και Επισκόπηση αρχείων εισόδου"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------------------+\n",
      "|Zip Code|Estimated Median Income|\n",
      "+--------+-----------------------+\n",
      "|   90001|                33887.0|\n",
      "|   90002|                30413.0|\n",
      "|   90003|                30805.0|\n",
      "|   90004|                40612.0|\n",
      "|   90005|                31142.0|\n",
      "+--------+-----------------------+\n",
      "only showing top 5 rows"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructField, StructType, StringType\n",
    "from pyspark.sql.functions import regexp_replace, col\n",
    "\n",
    "income_schema = StructType([\n",
    "    StructField(\"Zip Code\", StringType()),\n",
    "    StructField(\"Community\", StringType()),\n",
    "    StructField(\"Estimated Median Income\", StringType())\n",
    "])\n",
    "\n",
    "income_data = spark.read.csv(f\"{DATA_BUCKET}/LA_income_2015.csv\", header=True, schema=income_schema)\n",
    "\n",
    "# Μετατροπή του Estimated Median Income σε αριθμητική μορφή\n",
    "income_data = income_data \\\n",
    "    .withColumn(\n",
    "        \"Estimated Median Income\",\n",
    "        regexp_replace(col(\"Estimated Median Income\"), \"[$,]\", \"\").cast(\"float\")\n",
    "    ) \\\n",
    "    .select(\"Zip Code\", \"Estimated Median Income\")\n",
    "\n",
    "income_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+\n",
      "|    DR_NO|                geom|\n",
      "+---------+--------------------+\n",
      "|001307355|POINT (-118.2695 ...|\n",
      "|011401303|POINT (-118.3962 ...|\n",
      "|070309629|POINT (-118.2524 ...|\n",
      "|090631215|POINT (-118.3295 ...|\n",
      "|100100501|POINT (-118.2488 ...|\n",
      "+---------+--------------------+\n",
      "only showing top 5 rows"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructField, StructType, IntegerType, StringType, DoubleType\n",
    "\n",
    "# Ορισμός του schema των dataset\n",
    "crimes_schema = StructType([\n",
    "    StructField(\"DR_NO\", StringType()),\n",
    "    StructField(\"Date Rptd\", StringType()),\n",
    "    StructField(\"DATE OCC\", StringType()),\n",
    "    StructField(\"TIME OCC\", StringType()),\n",
    "    StructField(\"AREA\", IntegerType()),\n",
    "    StructField(\"AREA NAME\", StringType()),\n",
    "    StructField(\"Rpt Dist No\", StringType()),\n",
    "    StructField(\"Part 1-2\", IntegerType()),\n",
    "    StructField(\"Crm Cd\", IntegerType()),\n",
    "    StructField(\"Crm Cd Desc\", StringType()),\n",
    "    StructField(\"Mocodes\", StringType()),\n",
    "    StructField(\"Vict Age\", IntegerType()),\n",
    "    StructField(\"Vict Sex\", StringType()),\n",
    "    StructField(\"Vict Descent\", StringType()),\n",
    "    StructField(\"Premis Cd\", StringType()),\n",
    "    StructField(\"Premis Desc\", StringType()),\n",
    "    StructField(\"Weapon Used Cd\", IntegerType()),\n",
    "    StructField(\"Weapon Desc\", StringType()),\n",
    "    StructField(\"Status\", StringType()),\n",
    "    StructField(\"Status Desc\", StringType()),\n",
    "    StructField(\"Crm Cd 1\", IntegerType()),\n",
    "    StructField(\"Crm Cd 2\", IntegerType()),\n",
    "    StructField(\"Crm Cd 3\", IntegerType()),\n",
    "    StructField(\"Crm Cd 4\", IntegerType()),\n",
    "    StructField(\"LOCATION\", StringType()),\n",
    "    StructField(\"Cross Street\", StringType()),\n",
    "    StructField(\"LAT\", DoubleType()),\n",
    "    StructField(\"LON\", DoubleType())\n",
    "])\n",
    "\n",
    "# Διαβάζουμε τα 2 datasets (2010-2019 και 2020-σήμερα) και τα συνενώνουμε σε 1\n",
    "crime_data_2010_2019 = spark.read.csv(f\"{DATA_BUCKET}/CrimeData/Crime_Data_from_2010_to_2019_20241101.csv\", header=True, schema=crimes_schema)\n",
    "crime_data_2020_present = spark.read.csv(f\"{DATA_BUCKET}/CrimeData/Crime_Data_from_2020_to_Present_20241101.csv\", header=True, schema=crimes_schema)\n",
    "crime_data = crime_data_2010_2019.union(crime_data_2020_present)\n",
    "\n",
    "# Μετατρέπουμε τις στήλες LAT, LON σε geometry με το ST_POINT\n",
    "crime_data = crime_data \\\n",
    "                .withColumn(\"geom\", ST_Point(\"LON\", \"LAT\")) \\\n",
    "                .filter(col(\"geom\") != ST_Point(0, 0)) \\\n",
    "                .select(\"DR_NO\", \"geom\")\n",
    "\n",
    "crime_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+--------+--------------------+\n",
      "|     COMM|ZCTA10|POP_2010|            geometry|\n",
      "+---------+------+--------+--------------------+\n",
      "|San Pedro| 90732|      69|POLYGON ((-118.31...|\n",
      "|San Pedro| 90731|     120|POLYGON ((-118.28...|\n",
      "|San Pedro| 90731|     240|POLYGON ((-118.29...|\n",
      "|San Pedro| 90732|      75|POLYGON ((-118.31...|\n",
      "|San Pedro| 90731|     246|POLYGON ((-118.28...|\n",
      "+---------+------+--------+--------------------+\n",
      "only showing top 5 rows"
     ]
    }
   ],
   "source": [
    "blocks_df = sedona.read.format(\"geojson\") \\\n",
    "            .option(\"multiLine\", \"true\") \\\n",
    "            .load(f\"{DATA_BUCKET}/2010_Census_Blocks.geojson\") \\\n",
    "            .selectExpr(\"explode(features) as features\") \\\n",
    "            .select(\"features.*\")\n",
    "\n",
    "blocks_data = blocks_df.select( \\\n",
    "                [col(f\"properties.{col_name}\").alias(col_name) for col_name in \\\n",
    "                    blocks_df.schema[\"properties\"].dataType.fieldNames()] + [\"geometry\"]) \\\n",
    "            .drop(\"properties\") \\\n",
    "            .drop(\"type\") \\\n",
    "            .filter(col(\"COMM\").isNotNull() & (col(\"POP_2010\") > 0) & (col(\"CITY\") == \"Los Angeles\")) \\\n",
    "            .select(\"COMM\", \"ZCTA10\", \"POP_2010\", \"geometry\")\n",
    "\n",
    "blocks_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- COMM: string (nullable = true)\n",
      " |-- ZCTA10: string (nullable = true)\n",
      " |-- POP_2010: long (nullable = true)\n",
      " |-- geometry: geometry (nullable = true)"
     ]
    }
   ],
   "source": [
    "blocks_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+-------------------------------------------------------------------------+\n",
      "|field   |type    |meaning                                                                  |\n",
      "+--------+--------+-------------------------------------------------------------------------+\n",
      "|COMM    |string  |Unincorporated area community name and LA City neighborhood              |\n",
      "|POP_2010|long    |Population (PL 94-171 Redistricting Data Summary File - Total Population)|\n",
      "|ZCTA10  |string  |Zip Code Tabulation Area                                                 |\n",
      "|geometry|geometry|Geometry of the block                                                    |\n",
      "+--------+--------+-------------------------------------------------------------------------+"
     ]
    }
   ],
   "source": [
    "blocks_data_description_schema = StructType([\n",
    "    StructField(\"field\", StringType()),\n",
    "    StructField(\"type\", StringType()),\n",
    "    StructField(\"meaning\", StringType())\n",
    "])\n",
    "\n",
    "blocks_data_description = spark.read.csv(f\"{DATA_BUCKET}/2010_Census_Blocks_fields.csv\", header=True, schema=blocks_data_description_schema)\n",
    "\n",
    "blocks_data_description \\\n",
    "        .filter(col(\"field\").isin(\"COMM\", \"ZCTA10\", \"POP_2010\", \"geometry\")) \\\n",
    "        .show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Υλοποίηση με DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+-------------------+\n",
      "|                COMM| Income per Person|  Crimes per Person|\n",
      "+--------------------+------------------+-------------------+\n",
      "|       Glassell Park|352.32956381260095|0.42107565966612814|\n",
      "|          Silverlake| 435.3862970584675| 0.6938143081951338|\n",
      "|             Sunland| 595.2586013843649|0.46432206840390877|\n",
      "|     Atwater Village| 520.4056449897171| 0.5319480887880292|\n",
      "|     Hollywood Hills| 560.8047678795483| 0.7511023480910557|\n",
      "|Angeles National ...|          19414.65|               6.85|\n",
      "|      Mt. Washington| 386.5913058583402|0.45103574065227775|\n",
      "|             Tujunga|425.03878023290537|0.43214392355927145|\n",
      "|          Eagle Rock| 462.5070190802218| 0.4348379906058435|\n",
      "|          Sun Valley| 334.3990089158554| 0.5274401545154808|\n",
      "|       Highland Park|322.93648630829415| 0.4595841941013582|\n",
      "|    Lakeview Terrace|  404.909076483656| 0.4470802919708029|\n",
      "|           Los Feliz| 444.4558322794046|  0.776680610954373|\n",
      "|      Vermont Square|213.92902767920512| 0.7804116394606103|\n",
      "|              Venice|1315.4316934865901| 1.0748812260536398|\n",
      "|         Playa Vista| 490.7112928523415| 0.5004481290611696|\n",
      "|         Westchester| 604.7028968906845| 0.5666743028510736|\n",
      "|         West Vernon|142.88127236580516| 1.0376739562624255|\n",
      "|           Mar Vista| 593.2701017226397| 0.4221233962071257|\n",
      "|             Del Rey| 454.6839646556095|   0.48022742087347|\n",
      "+--------------------+------------------+-------------------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import sum, count, col\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Σύνδεση Εισοδήματος / Περιοχών με βάση το ZIP Code\n",
    "income_per_block = blocks_data \\\n",
    "                        .join(income_data, blocks_data[\"ZCTA10\"] == income_data[\"Zip Code\"]) \\\n",
    "                        .groupBy(\"COMM\") \\\n",
    "                        .agg( \\\n",
    "                            sum(\"POP_2010\").alias(\"Population\"), \\\n",
    "                            sum(\"Estimated Median Income\").alias(\"Total Income\") \\\n",
    "                        )\n",
    "\n",
    "# Σύνδεση Εγκλημάτων / Περιοχών με βάση το geometry, δηλαδή\n",
    "# το POINT του εγκλήματος βρίσκεται εντός του POLYGON της περιοχής\n",
    "crimes_per_block = crime_data \\\n",
    "                        .join(blocks_data, ST_Within(crime_data[\"geom\"], blocks_data[\"geometry\"]), \"inner\") \\\n",
    "                        .groupBy(\"COMM\") \\\n",
    "                        .agg(count(\"*\").alias(\"Total Crimes\"))\n",
    "\n",
    "# Aναλογία συνολικού αριθμού εγκλημάτων ανά άτομο\n",
    "result = income_per_block \\\n",
    "                .join(crimes_per_block, on=[\"COMM\"]) \\\n",
    "                .withColumn(\"Income per Person\", col(\"Total Income\") / col(\"Population\")) \\\n",
    "                .withColumn(\"Crimes per Person\", col(\"Total Crimes\") / col(\"Population\")) \\\n",
    "                .select(\"COMM\", \"Income per Person\", \"Crimes per Person\")\n",
    "\n",
    "result.show()\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 39.47 seconds"
     ]
    }
   ],
   "source": [
    "elapsed_time = end_time - start_time\n",
    "print(f\"Time taken: {elapsed_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan (36)\n",
      "+- Project (35)\n",
      "   +- SortMergeJoin Inner (34)\n",
      "      :- Sort (15)\n",
      "      :  +- HashAggregate (14)\n",
      "      :     +- Exchange (13)\n",
      "      :        +- HashAggregate (12)\n",
      "      :           +- Project (11)\n",
      "      :              +- BroadcastHashJoin Inner BuildRight (10)\n",
      "      :                 :- Project (5)\n",
      "      :                 :  +- Filter (4)\n",
      "      :                 :     +- Generate (3)\n",
      "      :                 :        +- Filter (2)\n",
      "      :                 :           +- Scan geojson  (1)\n",
      "      :                 +- BroadcastExchange (9)\n",
      "      :                    +- Project (8)\n",
      "      :                       +- Filter (7)\n",
      "      :                          +- Scan csv  (6)\n",
      "      +- Sort (33)\n",
      "         +- HashAggregate (32)\n",
      "            +- Exchange (31)\n",
      "               +- HashAggregate (30)\n",
      "                  +- Project (29)\n",
      "                     +- RangeJoin (28)\n",
      "                        :- Union (22)\n",
      "                        :  :- Project (18)\n",
      "                        :  :  +- Filter (17)\n",
      "                        :  :     +- Scan csv  (16)\n",
      "                        :  +- Project (21)\n",
      "                        :     +- Filter (20)\n",
      "                        :        +- Scan csv  (19)\n",
      "                        +- Project (27)\n",
      "                           +- Filter (26)\n",
      "                              +- Generate (25)\n",
      "                                 +- Filter (24)\n",
      "                                    +- Scan geojson  (23)\n",
      "\n",
      "\n",
      "(1) Scan geojson \n",
      "Output [1]: [features#239]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/2010_Census_Blocks.geojson]\n",
      "PushedFilters: [IsNotNull(features)]\n",
      "ReadSchema: struct<features:array<struct<geometry:binary,properties:struct<BG10:string,BG10FIP10:string,BG12:string,CB10:string,CEN_FIP13:string,CITY:string,CITYCOM:string,COMM:string,CT10:string,CT12:string,CTCB10:string,HD_2012:bigint,HD_NAME:string,HOUSING10:bigint,LA_FIP10:string,OBJECTID:bigint,POP_2010:bigint,PUMA10:string,SPA_2012:bigint,SPA_NAME:string,SUP_DIST:string,SUP_LABEL:string,ShapeSTArea:double,ShapeSTLength:double,ZCTA10:string>,type:string>>>\n",
      "\n",
      "(2) Filter\n",
      "Input [1]: [features#239]\n",
      "Condition : ((size(features#239, true) > 0) AND isnotnull(features#239))\n",
      "\n",
      "(3) Generate\n",
      "Input [1]: [features#239]\n",
      "Arguments: explode(features#239), false, [features#247]\n",
      "\n",
      "(4) Filter\n",
      "Input [1]: [features#247]\n",
      "Condition : (((isnotnull(features#247.properties.POP_2010) AND isnotnull(features#247.properties.CITY)) AND ((isnotnull(features#247.properties.COMM) AND (features#247.properties.POP_2010 > 0)) AND (features#247.properties.CITY = Los Angeles))) AND isnotnull(features#247.properties.ZCTA10))\n",
      "\n",
      "(5) Project\n",
      "Output [3]: [features#247.properties.COMM AS COMM#263, features#247.properties.ZCTA10 AS ZCTA10#280, features#247.properties.POP_2010 AS POP_2010#272L]\n",
      "Input [1]: [features#247]\n",
      "\n",
      "(6) Scan csv \n",
      "Output [2]: [Zip Code#24, Estimated Median Income#26]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/LA_income_2015.csv]\n",
      "PushedFilters: [IsNotNull(Zip Code)]\n",
      "ReadSchema: struct<Zip Code:string,Estimated Median Income:string>\n",
      "\n",
      "(7) Filter\n",
      "Input [2]: [Zip Code#24, Estimated Median Income#26]\n",
      "Condition : isnotnull(Zip Code#24)\n",
      "\n",
      "(8) Project\n",
      "Output [2]: [Zip Code#24, cast(regexp_replace(Estimated Median Income#26, [$,], , 1) as float) AS Estimated Median Income#30]\n",
      "Input [2]: [Zip Code#24, Estimated Median Income#26]\n",
      "\n",
      "(9) BroadcastExchange\n",
      "Input [2]: [Zip Code#24, Estimated Median Income#30]\n",
      "Arguments: HashedRelationBroadcastMode(List(input[0, string, false]),false), [plan_id=829]\n",
      "\n",
      "(10) BroadcastHashJoin\n",
      "Left keys [1]: [ZCTA10#280]\n",
      "Right keys [1]: [Zip Code#24]\n",
      "Join type: Inner\n",
      "Join condition: None\n",
      "\n",
      "(11) Project\n",
      "Output [3]: [COMM#263, POP_2010#272L, Estimated Median Income#30]\n",
      "Input [5]: [COMM#263, ZCTA10#280, POP_2010#272L, Zip Code#24, Estimated Median Income#30]\n",
      "\n",
      "(12) HashAggregate\n",
      "Input [3]: [COMM#263, POP_2010#272L, Estimated Median Income#30]\n",
      "Keys [1]: [COMM#263]\n",
      "Functions [2]: [partial_sum(POP_2010#272L), partial_sum(Estimated Median Income#30)]\n",
      "Aggregate Attributes [2]: [sum#544L, sum#546]\n",
      "Results [3]: [COMM#263, sum#545L, sum#547]\n",
      "\n",
      "(13) Exchange\n",
      "Input [3]: [COMM#263, sum#545L, sum#547]\n",
      "Arguments: hashpartitioning(COMM#263, 1000), ENSURE_REQUIREMENTS, [plan_id=834]\n",
      "\n",
      "(14) HashAggregate\n",
      "Input [3]: [COMM#263, sum#545L, sum#547]\n",
      "Keys [1]: [COMM#263]\n",
      "Functions [2]: [sum(POP_2010#272L), sum(Estimated Median Income#30)]\n",
      "Aggregate Attributes [2]: [sum(POP_2010#272L)#454L, sum(Estimated Median Income#30)#456]\n",
      "Results [3]: [COMM#263, sum(POP_2010#272L)#454L AS Population#455L, sum(Estimated Median Income#30)#456 AS Total Income#457]\n",
      "\n",
      "(15) Sort\n",
      "Input [3]: [COMM#263, Population#455L, Total Income#457]\n",
      "Arguments: [COMM#263 ASC NULLS FIRST], false, 0\n",
      "\n",
      "(16) Scan csv \n",
      "Output [2]: [LAT#74, LON#75]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_Data_from_2010_to_2019_20241101.csv]\n",
      "ReadSchema: struct<LAT:double,LON:double>\n",
      "\n",
      "(17) Filter\n",
      "Input [2]: [LAT#74, LON#75]\n",
      "Condition : NOT ( **org.apache.spark.sql.sedona_sql.expressions.ST_Point**   = 0x120000000100000000000000000000000000000000000000)\n",
      "\n",
      "(18) Project\n",
      "Output [1]: [ **org.apache.spark.sql.sedona_sql.expressions.ST_Point**   AS geom#188]\n",
      "Input [2]: [LAT#74, LON#75]\n",
      "\n",
      "(19) Scan csv \n",
      "Output [2]: [LAT#130, LON#131]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_Data_from_2020_to_Present_20241101.csv]\n",
      "ReadSchema: struct<LAT:double,LON:double>\n",
      "\n",
      "(20) Filter\n",
      "Input [2]: [LAT#130, LON#131]\n",
      "Condition : NOT ( **org.apache.spark.sql.sedona_sql.expressions.ST_Point**   = 0x120000000100000000000000000000000000000000000000)\n",
      "\n",
      "(21) Project\n",
      "Output [1]: [ **org.apache.spark.sql.sedona_sql.expressions.ST_Point**   AS geom#583]\n",
      "Input [2]: [LAT#130, LON#131]\n",
      "\n",
      "(22) Union\n",
      "\n",
      "(23) Scan geojson \n",
      "Output [1]: [features#484]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/2010_Census_Blocks.geojson]\n",
      "PushedFilters: [IsNotNull(features)]\n",
      "ReadSchema: struct<features:array<struct<geometry:binary,properties:struct<BG10:string,BG10FIP10:string,BG12:string,CB10:string,CEN_FIP13:string,CITY:string,CITYCOM:string,COMM:string,CT10:string,CT12:string,CTCB10:string,HD_2012:bigint,HD_NAME:string,HOUSING10:bigint,LA_FIP10:string,OBJECTID:bigint,POP_2010:bigint,PUMA10:string,SPA_2012:bigint,SPA_NAME:string,SUP_DIST:string,SUP_LABEL:string,ShapeSTArea:double,ShapeSTLength:double,ZCTA10:string>,type:string>>>\n",
      "\n",
      "(24) Filter\n",
      "Input [1]: [features#484]\n",
      "Condition : ((size(features#484, true) > 0) AND isnotnull(features#484))\n",
      "\n",
      "(25) Generate\n",
      "Input [1]: [features#484]\n",
      "Arguments: explode(features#484), false, [features#247]\n",
      "\n",
      "(26) Filter\n",
      "Input [1]: [features#247]\n",
      "Condition : (((((isnotnull(features#247.properties.POP_2010) AND isnotnull(features#247.properties.CITY)) AND isnotnull(features#247.properties.COMM)) AND (features#247.properties.POP_2010 > 0)) AND (features#247.properties.CITY = Los Angeles)) AND isnotnull(features#247.geometry))\n",
      "\n",
      "(27) Project\n",
      "Output [2]: [features#247.properties.COMM AS COMM#494, features#247.geometry AS geometry#250]\n",
      "Input [1]: [features#247]\n",
      "\n",
      "(28) RangeJoin\n",
      "Arguments: geom#188: geometry, geometry#250: geometry, WITHIN\n",
      "\n",
      "(29) Project\n",
      "Output [1]: [COMM#494]\n",
      "Input [3]: [geom#188, COMM#494, geometry#250]\n",
      "\n",
      "(30) HashAggregate\n",
      "Input [1]: [COMM#494]\n",
      "Keys [1]: [COMM#494]\n",
      "Functions [1]: [partial_count(1)]\n",
      "Aggregate Attributes [1]: [count#548L]\n",
      "Results [2]: [COMM#494, count#549L]\n",
      "\n",
      "(31) Exchange\n",
      "Input [2]: [COMM#494, count#549L]\n",
      "Arguments: hashpartitioning(COMM#494, 1000), ENSURE_REQUIREMENTS, [plan_id=907]\n",
      "\n",
      "(32) HashAggregate\n",
      "Input [2]: [COMM#494, count#549L]\n",
      "Keys [1]: [COMM#494]\n",
      "Functions [1]: [count(1)]\n",
      "Aggregate Attributes [1]: [count(1)#479L]\n",
      "Results [2]: [COMM#494, count(1)#479L AS Total Crimes#480L]\n",
      "\n",
      "(33) Sort\n",
      "Input [2]: [COMM#494, Total Crimes#480L]\n",
      "Arguments: [COMM#494 ASC NULLS FIRST], false, 0\n",
      "\n",
      "(34) SortMergeJoin\n",
      "Left keys [1]: [COMM#263]\n",
      "Right keys [1]: [COMM#494]\n",
      "Join type: Inner\n",
      "Join condition: None\n",
      "\n",
      "(35) Project\n",
      "Output [3]: [COMM#263, (Total Income#457 / cast(Population#455L as double)) AS Income per Person#517, (cast(Total Crimes#480L as double) / cast(Population#455L as double)) AS Crimes per Person#523]\n",
      "Input [5]: [COMM#263, Population#455L, Total Income#457, COMM#494, Total Crimes#480L]\n",
      "\n",
      "(36) AdaptiveSparkPlan\n",
      "Output [3]: [COMM#263, Income per Person#517, Crimes per Person#523]\n",
      "Arguments: isFinalPlan=false"
     ]
    }
   ],
   "source": [
    "result.explain(mode=\"formatted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Από προεπιλογή, το Spark χρησιμοποιεί τη στρατηγική **Sort Merge Join** (δηλαδή Merge).\n",
    "\n",
    "Θα δοκιμάσουμε να αναγκάσουμε το Spark να χρησιμοποιήσει διαφορετικές στρατηγικές, ώστε να συγκρίνουμε την απόδοσή τους."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. BROADCAST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d24c5a6f41af454c97dc49fac79c680d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An error was encountered:\n",
      "Invalid status code '400' from http://ec2-35-159-120-182.eu-central-1.compute.amazonaws.com:8998/sessions/914/statements/27 with error payload: {\"msg\":\"requirement failed: Session isn't active.\"}\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import sum, count, col\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Σύνδεση Εισοδήματος / Περιοχών\n",
    "income_per_block = blocks_data  \\\n",
    "                        .hint(\"BROADCAST\") \\\n",
    "                        .join(income_data, blocks_data[\"ZCTA10\"] == income_data[\"Zip Code\"]) \\\n",
    "                        .groupBy(\"COMM\") \\\n",
    "                        .agg( \\\n",
    "                            sum(\"POP_2010\").alias(\"Population\"), \\\n",
    "                            sum(\"Estimated Median Income\").alias(\"Total Income\") \\\n",
    "                        )\n",
    "\n",
    "# Σύνδεση Εγκλημάτων / Περιοχών\n",
    "crimes_per_block = crime_data \\\n",
    "                        .hint(\"BROADCAST\") \\\n",
    "                        .join(blocks_data, ST_Within(crime_data[\"geom\"], blocks_data[\"geometry\"]), \"inner\") \\\n",
    "                        .groupBy(\"COMM\") \\\n",
    "                        .agg(count(\"*\").alias(\"Total Crimes\"))\n",
    "\n",
    "# Aναλογία συνολικού αριθμού εγκλημάτων ανά άτομο\n",
    "result = income_per_block \\\n",
    "                .hint(\"BROADCAST\") \\\n",
    "                .join(crimes_per_block, on=[\"COMM\"]) \\\n",
    "                .withColumn(\"Income per Person\", col(\"Total Income\") / col(\"Population\")) \\\n",
    "                .withColumn(\"Crimes per Person\", col(\"Total Crimes\") / col(\"Population\")) \\\n",
    "                .select(\"COMM\", \"Income per Person\", \"Crimes per Person\")\n",
    "\n",
    "result.show()\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Το query δε μπορεί να εκτελεστεί με τη στρατηγική Broadcast στα join, λόγω του μεγάλου όγκου δεδομένων."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. MERGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+-------------------+\n",
      "|                COMM| Income per Person|  Crimes per Person|\n",
      "+--------------------+------------------+-------------------+\n",
      "|     Adams-Normandie|160.62637082376943| 0.7148686559551135|\n",
      "|              Alsace|186.29007503410642| 0.5416098226466576|\n",
      "|Angeles National ...|          19414.65|               6.85|\n",
      "|    Angelino Heights| 241.8594276094276| 0.5989057239057239|\n",
      "|              Arleta|312.64241391896826| 0.4264509064363061|\n",
      "|     Atwater Village| 520.4056449897171| 0.5319480887880292|\n",
      "|       Baldwin Hills| 146.9312427977791| 0.9974508502985648|\n",
      "|             Bel Air|1013.9382641326716|0.39922527539038855|\n",
      "|       Beverly Crest| 1226.391190222295| 0.3689607087195472|\n",
      "|         Beverlywood| 590.2408376963351| 0.5084977849375755|\n",
      "|       Boyle Heights|  169.583309101483| 0.6253271299796452|\n",
      "|           Brentwood| 842.1119757004881|0.40582232688304154|\n",
      "|           Brookside| 913.2125603864735| 0.8856682769726248|\n",
      "|    Cadillac-Corning|223.08117029257315|  0.581695423855964|\n",
      "|         Canoga Park|218.37461615459003| 0.5531784944777157|\n",
      "|             Carthay| 698.9462969996202|  0.781693885301937|\n",
      "|             Central|135.04158432612502| 0.6675512393427814|\n",
      "|        Century City| 660.3018502943651|  0.632968881412952|\n",
      "|  Century Palms/Cove|220.04783005343413|  1.150918806203571|\n",
      "|          Chatsworth| 586.4479175686207| 0.5337835887667042|\n",
      "+--------------------+------------------+-------------------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import sum, count, col\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Σύνδεση Εισοδήματος / Περιοχών με βάση το ZIP Code\n",
    "income_per_block = blocks_data  \\\n",
    "                        .hint(\"MERGE\") \\\n",
    "                        .join(income_data, blocks_data[\"ZCTA10\"] == income_data[\"Zip Code\"]) \\\n",
    "                        .groupBy(\"COMM\") \\\n",
    "                        .agg( \\\n",
    "                            sum(\"POP_2010\").alias(\"Population\"), \\\n",
    "                            sum(\"Estimated Median Income\").alias(\"Total Income\") \\\n",
    "                        )\n",
    "\n",
    "# Σύνδεση Εγκλημάτων / Περιοχών με βάση το geometry, δηλαδή\n",
    "# το POINT του εγκλήματος βρίσκεται εντός του POLYGON της περιοχής\n",
    "crimes_per_block = crime_data \\\n",
    "                        .hint(\"MERGE\") \\\n",
    "                        .join(blocks_data, ST_Within(crime_data[\"geom\"], blocks_data[\"geometry\"]), \"inner\") \\\n",
    "                        .groupBy(\"COMM\") \\\n",
    "                        .agg(count(\"*\").alias(\"Total Crimes\"))\n",
    "\n",
    "# Aναλογία συνολικού αριθμού εγκλημάτων ανά άτομο\n",
    "result = income_per_block \\\n",
    "                .hint(\"MERGE\") \\\n",
    "                .join(crimes_per_block, on=[\"COMM\"]) \\\n",
    "                .withColumn(\"Income per Person\", col(\"Total Income\") / col(\"Population\")) \\\n",
    "                .withColumn(\"Crimes per Person\", col(\"Total Crimes\") / col(\"Population\")) \\\n",
    "                .select(\"COMM\", \"Income per Person\", \"Crimes per Person\")\n",
    "\n",
    "result.show()\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 40.95 seconds"
     ]
    }
   ],
   "source": [
    "elapsed_time = end_time - start_time\n",
    "print(f\"Time taken: {elapsed_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan (39)\n",
      "+- Project (38)\n",
      "   +- SortMergeJoin Inner (37)\n",
      "      :- Sort (18)\n",
      "      :  +- HashAggregate (17)\n",
      "      :     +- Exchange (16)\n",
      "      :        +- HashAggregate (15)\n",
      "      :           +- Project (14)\n",
      "      :              +- SortMergeJoin Inner (13)\n",
      "      :                 :- Sort (7)\n",
      "      :                 :  +- Exchange (6)\n",
      "      :                 :     +- Project (5)\n",
      "      :                 :        +- Filter (4)\n",
      "      :                 :           +- Generate (3)\n",
      "      :                 :              +- Filter (2)\n",
      "      :                 :                 +- Scan geojson  (1)\n",
      "      :                 +- Sort (12)\n",
      "      :                    +- Exchange (11)\n",
      "      :                       +- Project (10)\n",
      "      :                          +- Filter (9)\n",
      "      :                             +- Scan csv  (8)\n",
      "      +- Sort (36)\n",
      "         +- HashAggregate (35)\n",
      "            +- Exchange (34)\n",
      "               +- HashAggregate (33)\n",
      "                  +- Project (32)\n",
      "                     +- RangeJoin (31)\n",
      "                        :- Union (25)\n",
      "                        :  :- Project (21)\n",
      "                        :  :  +- Filter (20)\n",
      "                        :  :     +- Scan csv  (19)\n",
      "                        :  +- Project (24)\n",
      "                        :     +- Filter (23)\n",
      "                        :        +- Scan csv  (22)\n",
      "                        +- Project (30)\n",
      "                           +- Filter (29)\n",
      "                              +- Generate (28)\n",
      "                                 +- Filter (27)\n",
      "                                    +- Scan geojson  (26)\n",
      "\n",
      "\n",
      "(1) Scan geojson \n",
      "Output [1]: [features#239]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/2010_Census_Blocks.geojson]\n",
      "PushedFilters: [IsNotNull(features)]\n",
      "ReadSchema: struct<features:array<struct<geometry:binary,properties:struct<BG10:string,BG10FIP10:string,BG12:string,CB10:string,CEN_FIP13:string,CITY:string,CITYCOM:string,COMM:string,CT10:string,CT12:string,CTCB10:string,HD_2012:bigint,HD_NAME:string,HOUSING10:bigint,LA_FIP10:string,OBJECTID:bigint,POP_2010:bigint,PUMA10:string,SPA_2012:bigint,SPA_NAME:string,SUP_DIST:string,SUP_LABEL:string,ShapeSTArea:double,ShapeSTLength:double,ZCTA10:string>,type:string>>>\n",
      "\n",
      "(2) Filter\n",
      "Input [1]: [features#239]\n",
      "Condition : ((size(features#239, true) > 0) AND isnotnull(features#239))\n",
      "\n",
      "(3) Generate\n",
      "Input [1]: [features#239]\n",
      "Arguments: explode(features#239), false, [features#247]\n",
      "\n",
      "(4) Filter\n",
      "Input [1]: [features#247]\n",
      "Condition : (((isnotnull(features#247.properties.POP_2010) AND isnotnull(features#247.properties.CITY)) AND ((isnotnull(features#247.properties.COMM) AND (features#247.properties.POP_2010 > 0)) AND (features#247.properties.CITY = Los Angeles))) AND isnotnull(features#247.properties.ZCTA10))\n",
      "\n",
      "(5) Project\n",
      "Output [3]: [features#247.properties.COMM AS COMM#263, features#247.properties.ZCTA10 AS ZCTA10#280, features#247.properties.POP_2010 AS POP_2010#272L]\n",
      "Input [1]: [features#247]\n",
      "\n",
      "(6) Exchange\n",
      "Input [3]: [COMM#263, ZCTA10#280, POP_2010#272L]\n",
      "Arguments: hashpartitioning(ZCTA10#280, 1000), ENSURE_REQUIREMENTS, [plan_id=1789]\n",
      "\n",
      "(7) Sort\n",
      "Input [3]: [COMM#263, ZCTA10#280, POP_2010#272L]\n",
      "Arguments: [ZCTA10#280 ASC NULLS FIRST], false, 0\n",
      "\n",
      "(8) Scan csv \n",
      "Output [2]: [Zip Code#24, Estimated Median Income#26]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/LA_income_2015.csv]\n",
      "PushedFilters: [IsNotNull(Zip Code)]\n",
      "ReadSchema: struct<Zip Code:string,Estimated Median Income:string>\n",
      "\n",
      "(9) Filter\n",
      "Input [2]: [Zip Code#24, Estimated Median Income#26]\n",
      "Condition : isnotnull(Zip Code#24)\n",
      "\n",
      "(10) Project\n",
      "Output [2]: [Zip Code#24, cast(regexp_replace(Estimated Median Income#26, [$,], , 1) as float) AS Estimated Median Income#30]\n",
      "Input [2]: [Zip Code#24, Estimated Median Income#26]\n",
      "\n",
      "(11) Exchange\n",
      "Input [2]: [Zip Code#24, Estimated Median Income#30]\n",
      "Arguments: hashpartitioning(Zip Code#24, 1000), ENSURE_REQUIREMENTS, [plan_id=1790]\n",
      "\n",
      "(12) Sort\n",
      "Input [2]: [Zip Code#24, Estimated Median Income#30]\n",
      "Arguments: [Zip Code#24 ASC NULLS FIRST], false, 0\n",
      "\n",
      "(13) SortMergeJoin\n",
      "Left keys [1]: [ZCTA10#280]\n",
      "Right keys [1]: [Zip Code#24]\n",
      "Join type: Inner\n",
      "Join condition: None\n",
      "\n",
      "(14) Project\n",
      "Output [3]: [COMM#263, POP_2010#272L, Estimated Median Income#30]\n",
      "Input [5]: [COMM#263, ZCTA10#280, POP_2010#272L, Zip Code#24, Estimated Median Income#30]\n",
      "\n",
      "(15) HashAggregate\n",
      "Input [3]: [COMM#263, POP_2010#272L, Estimated Median Income#30]\n",
      "Keys [1]: [COMM#263]\n",
      "Functions [2]: [partial_sum(POP_2010#272L), partial_sum(Estimated Median Income#30)]\n",
      "Aggregate Attributes [2]: [sum#699L, sum#701]\n",
      "Results [3]: [COMM#263, sum#700L, sum#702]\n",
      "\n",
      "(16) Exchange\n",
      "Input [3]: [COMM#263, sum#700L, sum#702]\n",
      "Arguments: hashpartitioning(COMM#263, 1000), ENSURE_REQUIREMENTS, [plan_id=1797]\n",
      "\n",
      "(17) HashAggregate\n",
      "Input [3]: [COMM#263, sum#700L, sum#702]\n",
      "Keys [1]: [COMM#263]\n",
      "Functions [2]: [sum(POP_2010#272L), sum(Estimated Median Income#30)]\n",
      "Aggregate Attributes [2]: [sum(POP_2010#272L)#609L, sum(Estimated Median Income#30)#611]\n",
      "Results [3]: [COMM#263, sum(POP_2010#272L)#609L AS Population#610L, sum(Estimated Median Income#30)#611 AS Total Income#612]\n",
      "\n",
      "(18) Sort\n",
      "Input [3]: [COMM#263, Population#610L, Total Income#612]\n",
      "Arguments: [COMM#263 ASC NULLS FIRST], false, 0\n",
      "\n",
      "(19) Scan csv \n",
      "Output [2]: [LAT#74, LON#75]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_Data_from_2010_to_2019_20241101.csv]\n",
      "ReadSchema: struct<LAT:double,LON:double>\n",
      "\n",
      "(20) Filter\n",
      "Input [2]: [LAT#74, LON#75]\n",
      "Condition : NOT ( **org.apache.spark.sql.sedona_sql.expressions.ST_Point**   = 0x120000000100000000000000000000000000000000000000)\n",
      "\n",
      "(21) Project\n",
      "Output [1]: [ **org.apache.spark.sql.sedona_sql.expressions.ST_Point**   AS geom#188]\n",
      "Input [2]: [LAT#74, LON#75]\n",
      "\n",
      "(22) Scan csv \n",
      "Output [2]: [LAT#130, LON#131]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_Data_from_2020_to_Present_20241101.csv]\n",
      "ReadSchema: struct<LAT:double,LON:double>\n",
      "\n",
      "(23) Filter\n",
      "Input [2]: [LAT#130, LON#131]\n",
      "Condition : NOT ( **org.apache.spark.sql.sedona_sql.expressions.ST_Point**   = 0x120000000100000000000000000000000000000000000000)\n",
      "\n",
      "(24) Project\n",
      "Output [1]: [ **org.apache.spark.sql.sedona_sql.expressions.ST_Point**   AS geom#738]\n",
      "Input [2]: [LAT#130, LON#131]\n",
      "\n",
      "(25) Union\n",
      "\n",
      "(26) Scan geojson \n",
      "Output [1]: [features#639]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/2010_Census_Blocks.geojson]\n",
      "PushedFilters: [IsNotNull(features)]\n",
      "ReadSchema: struct<features:array<struct<geometry:binary,properties:struct<BG10:string,BG10FIP10:string,BG12:string,CB10:string,CEN_FIP13:string,CITY:string,CITYCOM:string,COMM:string,CT10:string,CT12:string,CTCB10:string,HD_2012:bigint,HD_NAME:string,HOUSING10:bigint,LA_FIP10:string,OBJECTID:bigint,POP_2010:bigint,PUMA10:string,SPA_2012:bigint,SPA_NAME:string,SUP_DIST:string,SUP_LABEL:string,ShapeSTArea:double,ShapeSTLength:double,ZCTA10:string>,type:string>>>\n",
      "\n",
      "(27) Filter\n",
      "Input [1]: [features#639]\n",
      "Condition : ((size(features#639, true) > 0) AND isnotnull(features#639))\n",
      "\n",
      "(28) Generate\n",
      "Input [1]: [features#639]\n",
      "Arguments: explode(features#639), false, [features#247]\n",
      "\n",
      "(29) Filter\n",
      "Input [1]: [features#247]\n",
      "Condition : ((((((isnotnull(features#247.properties.POP_2010) AND isnotnull(features#247.properties.CITY)) AND isnotnull(features#247.properties.COMM)) AND (features#247.properties.POP_2010 > 0)) AND (features#247.properties.CITY = Los Angeles)) AND isnotnull(features#247.geometry)) AND bloomfilter#739 of [bf739 COMM#263 estimatedNumRows=294857] filtering [features#247.properties.COMM])\n",
      "\n",
      "(30) Project\n",
      "Output [2]: [features#247.properties.COMM AS COMM#649, features#247.geometry AS geometry#250]\n",
      "Input [1]: [features#247]\n",
      "\n",
      "(31) RangeJoin\n",
      "Arguments: geom#188: geometry, geometry#250: geometry, WITHIN\n",
      "\n",
      "(32) Project\n",
      "Output [1]: [COMM#649]\n",
      "Input [3]: [geom#188, COMM#649, geometry#250]\n",
      "\n",
      "(33) HashAggregate\n",
      "Input [1]: [COMM#649]\n",
      "Keys [1]: [COMM#649]\n",
      "Functions [1]: [partial_count(1)]\n",
      "Aggregate Attributes [1]: [count#703L]\n",
      "Results [2]: [COMM#649, count#704L]\n",
      "\n",
      "(34) Exchange\n",
      "Input [2]: [COMM#649, count#704L]\n",
      "Arguments: hashpartitioning(COMM#649, 1000), ENSURE_REQUIREMENTS, [plan_id=1885]\n",
      "\n",
      "(35) HashAggregate\n",
      "Input [2]: [COMM#649, count#704L]\n",
      "Keys [1]: [COMM#649]\n",
      "Functions [1]: [count(1)]\n",
      "Aggregate Attributes [1]: [count(1)#634L]\n",
      "Results [2]: [COMM#649, count(1)#634L AS Total Crimes#635L]\n",
      "\n",
      "(36) Sort\n",
      "Input [2]: [COMM#649, Total Crimes#635L]\n",
      "Arguments: [COMM#649 ASC NULLS FIRST], false, 0\n",
      "\n",
      "(37) SortMergeJoin\n",
      "Left keys [1]: [COMM#263]\n",
      "Right keys [1]: [COMM#649]\n",
      "Join type: Inner\n",
      "Join condition: None\n",
      "\n",
      "(38) Project\n",
      "Output [3]: [COMM#263, (Total Income#612 / cast(Population#610L as double)) AS Income per Person#672, (cast(Total Crimes#635L as double) / cast(Population#610L as double)) AS Crimes per Person#678]\n",
      "Input [5]: [COMM#263, Population#610L, Total Income#612, COMM#649, Total Crimes#635L]\n",
      "\n",
      "(39) AdaptiveSparkPlan\n",
      "Output [3]: [COMM#263, Income per Person#672, Crimes per Person#678]\n",
      "Arguments: isFinalPlan=false\n",
      "\n",
      "===== Subqueries =====\n",
      "\n",
      "Subquery:1 Hosting operator id = 29 Hosting Expression = bloomfilter#739 of [bf739 COMM#263 estimatedNumRows=294857] filtering [features#247.properties.COMM]\n",
      "OutputAdapter (47)\n",
      "+- AdaptiveSparkPlan (46)\n",
      "   +- Exchange (45)\n",
      "      +- Project (44)\n",
      "         +- Filter (43)\n",
      "            +- Generate (42)\n",
      "               +- Filter (41)\n",
      "                  +- Scan geojson  (40)\n",
      "\n",
      "\n",
      "(40) Scan geojson \n",
      "Output [1]: [features#239]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/2010_Census_Blocks.geojson]\n",
      "PushedFilters: [IsNotNull(features)]\n",
      "ReadSchema: struct<features:array<struct<geometry:binary,properties:struct<BG10:string,BG10FIP10:string,BG12:string,CB10:string,CEN_FIP13:string,CITY:string,CITYCOM:string,COMM:string,CT10:string,CT12:string,CTCB10:string,HD_2012:bigint,HD_NAME:string,HOUSING10:bigint,LA_FIP10:string,OBJECTID:bigint,POP_2010:bigint,PUMA10:string,SPA_2012:bigint,SPA_NAME:string,SUP_DIST:string,SUP_LABEL:string,ShapeSTArea:double,ShapeSTLength:double,ZCTA10:string>,type:string>>>\n",
      "\n",
      "(41) Filter\n",
      "Input [1]: [features#239]\n",
      "Condition : ((size(features#239, true) > 0) AND isnotnull(features#239))\n",
      "\n",
      "(42) Generate\n",
      "Input [1]: [features#239]\n",
      "Arguments: explode(features#239), false, [features#247]\n",
      "\n",
      "(43) Filter\n",
      "Input [1]: [features#247]\n",
      "Condition : (((isnotnull(features#247.properties.POP_2010) AND isnotnull(features#247.properties.CITY)) AND ((isnotnull(features#247.properties.COMM) AND (features#247.properties.POP_2010 > 0)) AND (features#247.properties.CITY = Los Angeles))) AND isnotnull(features#247.properties.ZCTA10))\n",
      "\n",
      "(44) Project\n",
      "Output [3]: [features#247.properties.COMM AS COMM#263, features#247.properties.ZCTA10 AS ZCTA10#280, features#247.properties.POP_2010 AS POP_2010#272L]\n",
      "Input [1]: [features#247]\n",
      "\n",
      "(45) Exchange\n",
      "Input [3]: [COMM#263, ZCTA10#280, POP_2010#272L]\n",
      "Arguments: hashpartitioning(ZCTA10#280, 1000), ENSURE_REQUIREMENTS, [plan_id=1876]\n",
      "\n",
      "(46) AdaptiveSparkPlan\n",
      "Output [3]: [COMM#263, ZCTA10#280, POP_2010#272L]\n",
      "Arguments: isFinalPlan=false\n",
      "\n",
      "(47) OutputAdapter\n",
      "Output [3]: [COMM#263, ZCTA10#280, POP_2010#272L]"
     ]
    }
   ],
   "source": [
    "result.explain(mode=\"formatted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. SHUFFLE HASH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+-------------------+\n",
      "|                COMM| Income per Person|  Crimes per Person|\n",
      "+--------------------+------------------+-------------------+\n",
      "|      Gramercy Place| 488.9200849338867| 1.0647620886014864|\n",
      "|         Westchester| 604.7028968906845| 0.5666743028510736|\n",
      "|      Harbor Gateway| 323.6666832768587|0.46035977675901935|\n",
      "|         Playa Vista| 490.7112928523415| 0.5004481290611696|\n",
      "|       Playa Del Rey| 1351.127295756808| 0.7425585813806207|\n",
      "|    Marina Peninsula| 2595.523172700023| 0.5999538851740834|\n",
      "|   Manchester Square|452.35297684006304| 1.0803928701345944|\n",
      "|      Vermont Knolls|208.44291881520567| 1.0672142942798897|\n",
      "|        Harvard Park| 260.5980739155486| 1.0106455949735231|\n",
      "|           Hyde Park|  340.338796836417|  1.031421107254053|\n",
      "|       Cheviot Hills|1145.7122908123683| 0.5429458051645794|\n",
      "|    West Los Angeles|465.24153373335287| 0.6377579394116786|\n",
      "|         Beverlywood| 590.2408376963351| 0.5084977849375755|\n",
      "|           Mar Vista| 593.2701017226397| 0.4221233962071257|\n",
      "|        Century City| 660.3018502943651|  0.632968881412952|\n",
      "|         Rancho Park| 1012.177760127085| 1.0413026211278793|\n",
      "|               Palms|220.17384277685312|  0.431748558747618|\n",
      "|  Century Palms/Cove|220.04783005343413|  1.150918806203571|\n",
      "|Figueroa Park Square|243.88770699867038| 0.9162335307627221|\n",
      "|         Harbor City|359.89346237994584| 0.5141469203100085|\n",
      "+--------------------+------------------+-------------------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import sum, count, col\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Σύνδεση Εισοδήματος / Περιοχών με βάση το ZIP Code\n",
    "income_per_block = blocks_data  \\\n",
    "                        .hint(\"SHUFFLE_HASH\") \\\n",
    "                        .join(income_data, blocks_data[\"ZCTA10\"] == income_data[\"Zip Code\"]) \\\n",
    "                        .groupBy(\"COMM\") \\\n",
    "                        .agg( \\\n",
    "                            sum(\"POP_2010\").alias(\"Population\"), \\\n",
    "                            sum(\"Estimated Median Income\").alias(\"Total Income\") \\\n",
    "                        )\n",
    "\n",
    "# Σύνδεση Εγκλημάτων / Περιοχών με βάση το geometry, δηλαδή\n",
    "# το POINT του εγκλήματος βρίσκεται εντός του POLYGON της περιοχής\n",
    "crimes_per_block = crime_data \\\n",
    "                        .hint(\"SHUFFLE_HASH\") \\\n",
    "                        .join(blocks_data, ST_Within(crime_data[\"geom\"], blocks_data[\"geometry\"]), \"inner\") \\\n",
    "                        .groupBy(\"COMM\") \\\n",
    "                        .agg(count(\"*\").alias(\"Total Crimes\"))\n",
    "\n",
    "# Aναλογία συνολικού αριθμού εγκλημάτων ανά άτομο\n",
    "result = income_per_block \\\n",
    "                .hint(\"SHUFFLE_HASH\") \\\n",
    "                .join(crimes_per_block, on=[\"COMM\"]) \\\n",
    "                .withColumn(\"Income per Person\", col(\"Total Income\") / col(\"Population\")) \\\n",
    "                .withColumn(\"Crimes per Person\", col(\"Total Crimes\") / col(\"Population\")) \\\n",
    "                .select(\"COMM\", \"Income per Person\", \"Crimes per Person\")\n",
    "\n",
    "result.show()\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 29.44 seconds"
     ]
    }
   ],
   "source": [
    "elapsed_time = end_time - start_time\n",
    "print(f\"Time taken: {elapsed_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan (35)\n",
      "+- Project (34)\n",
      "   +- ShuffledHashJoin Inner BuildLeft (33)\n",
      "      :- HashAggregate (15)\n",
      "      :  +- Exchange (14)\n",
      "      :     +- HashAggregate (13)\n",
      "      :        +- Project (12)\n",
      "      :           +- ShuffledHashJoin Inner BuildLeft (11)\n",
      "      :              :- Exchange (6)\n",
      "      :              :  +- Project (5)\n",
      "      :              :     +- Filter (4)\n",
      "      :              :        +- Generate (3)\n",
      "      :              :           +- Filter (2)\n",
      "      :              :              +- Scan geojson  (1)\n",
      "      :              +- Exchange (10)\n",
      "      :                 +- Project (9)\n",
      "      :                    +- Filter (8)\n",
      "      :                       +- Scan csv  (7)\n",
      "      +- HashAggregate (32)\n",
      "         +- Exchange (31)\n",
      "            +- HashAggregate (30)\n",
      "               +- Project (29)\n",
      "                  +- RangeJoin (28)\n",
      "                     :- Union (22)\n",
      "                     :  :- Project (18)\n",
      "                     :  :  +- Filter (17)\n",
      "                     :  :     +- Scan csv  (16)\n",
      "                     :  +- Project (21)\n",
      "                     :     +- Filter (20)\n",
      "                     :        +- Scan csv  (19)\n",
      "                     +- Project (27)\n",
      "                        +- Filter (26)\n",
      "                           +- Generate (25)\n",
      "                              +- Filter (24)\n",
      "                                 +- Scan geojson  (23)\n",
      "\n",
      "\n",
      "(1) Scan geojson \n",
      "Output [1]: [features#239]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/2010_Census_Blocks.geojson]\n",
      "PushedFilters: [IsNotNull(features)]\n",
      "ReadSchema: struct<features:array<struct<geometry:binary,properties:struct<BG10:string,BG10FIP10:string,BG12:string,CB10:string,CEN_FIP13:string,CITY:string,CITYCOM:string,COMM:string,CT10:string,CT12:string,CTCB10:string,HD_2012:bigint,HD_NAME:string,HOUSING10:bigint,LA_FIP10:string,OBJECTID:bigint,POP_2010:bigint,PUMA10:string,SPA_2012:bigint,SPA_NAME:string,SUP_DIST:string,SUP_LABEL:string,ShapeSTArea:double,ShapeSTLength:double,ZCTA10:string>,type:string>>>\n",
      "\n",
      "(2) Filter\n",
      "Input [1]: [features#239]\n",
      "Condition : ((size(features#239, true) > 0) AND isnotnull(features#239))\n",
      "\n",
      "(3) Generate\n",
      "Input [1]: [features#239]\n",
      "Arguments: explode(features#239), false, [features#247]\n",
      "\n",
      "(4) Filter\n",
      "Input [1]: [features#247]\n",
      "Condition : (((isnotnull(features#247.properties.POP_2010) AND isnotnull(features#247.properties.CITY)) AND ((isnotnull(features#247.properties.COMM) AND (features#247.properties.POP_2010 > 0)) AND (features#247.properties.CITY = Los Angeles))) AND isnotnull(features#247.properties.ZCTA10))\n",
      "\n",
      "(5) Project\n",
      "Output [3]: [features#247.properties.COMM AS COMM#263, features#247.properties.ZCTA10 AS ZCTA10#280, features#247.properties.POP_2010 AS POP_2010#272L]\n",
      "Input [1]: [features#247]\n",
      "\n",
      "(6) Exchange\n",
      "Input [3]: [COMM#263, ZCTA10#280, POP_2010#272L]\n",
      "Arguments: hashpartitioning(ZCTA10#280, 1000), ENSURE_REQUIREMENTS, [plan_id=2694]\n",
      "\n",
      "(7) Scan csv \n",
      "Output [2]: [Zip Code#24, Estimated Median Income#26]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/LA_income_2015.csv]\n",
      "PushedFilters: [IsNotNull(Zip Code)]\n",
      "ReadSchema: struct<Zip Code:string,Estimated Median Income:string>\n",
      "\n",
      "(8) Filter\n",
      "Input [2]: [Zip Code#24, Estimated Median Income#26]\n",
      "Condition : isnotnull(Zip Code#24)\n",
      "\n",
      "(9) Project\n",
      "Output [2]: [Zip Code#24, cast(regexp_replace(Estimated Median Income#26, [$,], , 1) as float) AS Estimated Median Income#30]\n",
      "Input [2]: [Zip Code#24, Estimated Median Income#26]\n",
      "\n",
      "(10) Exchange\n",
      "Input [2]: [Zip Code#24, Estimated Median Income#30]\n",
      "Arguments: hashpartitioning(Zip Code#24, 1000), ENSURE_REQUIREMENTS, [plan_id=2695]\n",
      "\n",
      "(11) ShuffledHashJoin\n",
      "Left keys [1]: [ZCTA10#280]\n",
      "Right keys [1]: [Zip Code#24]\n",
      "Join type: Inner\n",
      "Join condition: None\n",
      "\n",
      "(12) Project\n",
      "Output [3]: [COMM#263, POP_2010#272L, Estimated Median Income#30]\n",
      "Input [5]: [COMM#263, ZCTA10#280, POP_2010#272L, Zip Code#24, Estimated Median Income#30]\n",
      "\n",
      "(13) HashAggregate\n",
      "Input [3]: [COMM#263, POP_2010#272L, Estimated Median Income#30]\n",
      "Keys [1]: [COMM#263]\n",
      "Functions [2]: [partial_sum(POP_2010#272L), partial_sum(Estimated Median Income#30)]\n",
      "Aggregate Attributes [2]: [sum#854L, sum#856]\n",
      "Results [3]: [COMM#263, sum#855L, sum#857]\n",
      "\n",
      "(14) Exchange\n",
      "Input [3]: [COMM#263, sum#855L, sum#857]\n",
      "Arguments: hashpartitioning(COMM#263, 1000), ENSURE_REQUIREMENTS, [plan_id=2700]\n",
      "\n",
      "(15) HashAggregate\n",
      "Input [3]: [COMM#263, sum#855L, sum#857]\n",
      "Keys [1]: [COMM#263]\n",
      "Functions [2]: [sum(POP_2010#272L), sum(Estimated Median Income#30)]\n",
      "Aggregate Attributes [2]: [sum(POP_2010#272L)#764L, sum(Estimated Median Income#30)#766]\n",
      "Results [3]: [COMM#263, sum(POP_2010#272L)#764L AS Population#765L, sum(Estimated Median Income#30)#766 AS Total Income#767]\n",
      "\n",
      "(16) Scan csv \n",
      "Output [2]: [LAT#74, LON#75]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_Data_from_2010_to_2019_20241101.csv]\n",
      "ReadSchema: struct<LAT:double,LON:double>\n",
      "\n",
      "(17) Filter\n",
      "Input [2]: [LAT#74, LON#75]\n",
      "Condition : NOT ( **org.apache.spark.sql.sedona_sql.expressions.ST_Point**   = 0x120000000100000000000000000000000000000000000000)\n",
      "\n",
      "(18) Project\n",
      "Output [1]: [ **org.apache.spark.sql.sedona_sql.expressions.ST_Point**   AS geom#188]\n",
      "Input [2]: [LAT#74, LON#75]\n",
      "\n",
      "(19) Scan csv \n",
      "Output [2]: [LAT#130, LON#131]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_Data_from_2020_to_Present_20241101.csv]\n",
      "ReadSchema: struct<LAT:double,LON:double>\n",
      "\n",
      "(20) Filter\n",
      "Input [2]: [LAT#130, LON#131]\n",
      "Condition : NOT ( **org.apache.spark.sql.sedona_sql.expressions.ST_Point**   = 0x120000000100000000000000000000000000000000000000)\n",
      "\n",
      "(21) Project\n",
      "Output [1]: [ **org.apache.spark.sql.sedona_sql.expressions.ST_Point**   AS geom#893]\n",
      "Input [2]: [LAT#130, LON#131]\n",
      "\n",
      "(22) Union\n",
      "\n",
      "(23) Scan geojson \n",
      "Output [1]: [features#794]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/2010_Census_Blocks.geojson]\n",
      "PushedFilters: [IsNotNull(features)]\n",
      "ReadSchema: struct<features:array<struct<geometry:binary,properties:struct<BG10:string,BG10FIP10:string,BG12:string,CB10:string,CEN_FIP13:string,CITY:string,CITYCOM:string,COMM:string,CT10:string,CT12:string,CTCB10:string,HD_2012:bigint,HD_NAME:string,HOUSING10:bigint,LA_FIP10:string,OBJECTID:bigint,POP_2010:bigint,PUMA10:string,SPA_2012:bigint,SPA_NAME:string,SUP_DIST:string,SUP_LABEL:string,ShapeSTArea:double,ShapeSTLength:double,ZCTA10:string>,type:string>>>\n",
      "\n",
      "(24) Filter\n",
      "Input [1]: [features#794]\n",
      "Condition : ((size(features#794, true) > 0) AND isnotnull(features#794))\n",
      "\n",
      "(25) Generate\n",
      "Input [1]: [features#794]\n",
      "Arguments: explode(features#794), false, [features#247]\n",
      "\n",
      "(26) Filter\n",
      "Input [1]: [features#247]\n",
      "Condition : ((((((isnotnull(features#247.properties.POP_2010) AND isnotnull(features#247.properties.CITY)) AND isnotnull(features#247.properties.COMM)) AND (features#247.properties.POP_2010 > 0)) AND (features#247.properties.CITY = Los Angeles)) AND isnotnull(features#247.geometry)) AND bloomfilter#894 of [bf894 COMM#263 estimatedNumRows=294857] filtering [features#247.properties.COMM])\n",
      "\n",
      "(27) Project\n",
      "Output [2]: [features#247.properties.COMM AS COMM#804, features#247.geometry AS geometry#250]\n",
      "Input [1]: [features#247]\n",
      "\n",
      "(28) RangeJoin\n",
      "Arguments: geom#188: geometry, geometry#250: geometry, WITHIN\n",
      "\n",
      "(29) Project\n",
      "Output [1]: [COMM#804]\n",
      "Input [3]: [geom#188, COMM#804, geometry#250]\n",
      "\n",
      "(30) HashAggregate\n",
      "Input [1]: [COMM#804]\n",
      "Keys [1]: [COMM#804]\n",
      "Functions [1]: [partial_count(1)]\n",
      "Aggregate Attributes [1]: [count#858L]\n",
      "Results [2]: [COMM#804, count#859L]\n",
      "\n",
      "(31) Exchange\n",
      "Input [2]: [COMM#804, count#859L]\n",
      "Arguments: hashpartitioning(COMM#804, 1000), ENSURE_REQUIREMENTS, [plan_id=2781]\n",
      "\n",
      "(32) HashAggregate\n",
      "Input [2]: [COMM#804, count#859L]\n",
      "Keys [1]: [COMM#804]\n",
      "Functions [1]: [count(1)]\n",
      "Aggregate Attributes [1]: [count(1)#789L]\n",
      "Results [2]: [COMM#804, count(1)#789L AS Total Crimes#790L]\n",
      "\n",
      "(33) ShuffledHashJoin\n",
      "Left keys [1]: [COMM#263]\n",
      "Right keys [1]: [COMM#804]\n",
      "Join type: Inner\n",
      "Join condition: None\n",
      "\n",
      "(34) Project\n",
      "Output [3]: [COMM#263, (Total Income#767 / cast(Population#765L as double)) AS Income per Person#827, (cast(Total Crimes#790L as double) / cast(Population#765L as double)) AS Crimes per Person#833]\n",
      "Input [5]: [COMM#263, Population#765L, Total Income#767, COMM#804, Total Crimes#790L]\n",
      "\n",
      "(35) AdaptiveSparkPlan\n",
      "Output [3]: [COMM#263, Income per Person#827, Crimes per Person#833]\n",
      "Arguments: isFinalPlan=false\n",
      "\n",
      "===== Subqueries =====\n",
      "\n",
      "Subquery:1 Hosting operator id = 26 Hosting Expression = bloomfilter#894 of [bf894 COMM#263 estimatedNumRows=294857] filtering [features#247.properties.COMM]\n",
      "OutputAdapter (43)\n",
      "+- AdaptiveSparkPlan (42)\n",
      "   +- Exchange (41)\n",
      "      +- Project (40)\n",
      "         +- Filter (39)\n",
      "            +- Generate (38)\n",
      "               +- Filter (37)\n",
      "                  +- Scan geojson  (36)\n",
      "\n",
      "\n",
      "(36) Scan geojson \n",
      "Output [1]: [features#239]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/2010_Census_Blocks.geojson]\n",
      "PushedFilters: [IsNotNull(features)]\n",
      "ReadSchema: struct<features:array<struct<geometry:binary,properties:struct<BG10:string,BG10FIP10:string,BG12:string,CB10:string,CEN_FIP13:string,CITY:string,CITYCOM:string,COMM:string,CT10:string,CT12:string,CTCB10:string,HD_2012:bigint,HD_NAME:string,HOUSING10:bigint,LA_FIP10:string,OBJECTID:bigint,POP_2010:bigint,PUMA10:string,SPA_2012:bigint,SPA_NAME:string,SUP_DIST:string,SUP_LABEL:string,ShapeSTArea:double,ShapeSTLength:double,ZCTA10:string>,type:string>>>\n",
      "\n",
      "(37) Filter\n",
      "Input [1]: [features#239]\n",
      "Condition : ((size(features#239, true) > 0) AND isnotnull(features#239))\n",
      "\n",
      "(38) Generate\n",
      "Input [1]: [features#239]\n",
      "Arguments: explode(features#239), false, [features#247]\n",
      "\n",
      "(39) Filter\n",
      "Input [1]: [features#247]\n",
      "Condition : (((isnotnull(features#247.properties.POP_2010) AND isnotnull(features#247.properties.CITY)) AND ((isnotnull(features#247.properties.COMM) AND (features#247.properties.POP_2010 > 0)) AND (features#247.properties.CITY = Los Angeles))) AND isnotnull(features#247.properties.ZCTA10))\n",
      "\n",
      "(40) Project\n",
      "Output [3]: [features#247.properties.COMM AS COMM#263, features#247.properties.ZCTA10 AS ZCTA10#280, features#247.properties.POP_2010 AS POP_2010#272L]\n",
      "Input [1]: [features#247]\n",
      "\n",
      "(41) Exchange\n",
      "Input [3]: [COMM#263, ZCTA10#280, POP_2010#272L]\n",
      "Arguments: hashpartitioning(ZCTA10#280, 1000), ENSURE_REQUIREMENTS, [plan_id=2772]\n",
      "\n",
      "(42) AdaptiveSparkPlan\n",
      "Output [3]: [COMM#263, ZCTA10#280, POP_2010#272L]\n",
      "Arguments: isFinalPlan=false\n",
      "\n",
      "(43) OutputAdapter\n",
      "Output [3]: [COMM#263, ZCTA10#280, POP_2010#272L]"
     ]
    }
   ],
   "source": [
    "result.explain(mode=\"formatted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. SHUFFLE REPLICATE NL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+-------------------+\n",
      "|              COMM| Income per Person|  Crimes per Person|\n",
      "+------------------+------------------+-------------------+\n",
      "|    Toluca Terrace| 260.9477325134512|0.22213681783243658|\n",
      "|      Elysian Park| 189.6804632618189| 0.6058477311562559|\n",
      "|          Longwood|209.40380047505937| 0.7273159144893112|\n",
      "|     Green Meadows|246.80379395590535| 1.1079662983704153|\n",
      "|  Cadillac-Corning|223.08117029257315|  0.581695423855964|\n",
      "|          Mid-city|396.23837087663014| 0.7106492781923426|\n",
      "|   Lincoln Heights|207.09009761109684| 0.5137105060364757|\n",
      "|          Van Nuys|148.04583871005244|  0.787558562643137|\n",
      "|    Gramercy Place| 488.9200849338867| 1.0647620886014864|\n",
      "| Faircrest Heights| 624.6238745280278| 0.7290153935521347|\n",
      "|     Boyle Heights|  169.583309101483| 0.6253271299796452|\n",
      "|  Lafayette Square|243.89444699403396| 0.8049564020192749|\n",
      "|     Granada Hills| 638.8912673095048| 0.5292539694047705|\n",
      "|       North Hills|243.40044345898005|  0.617259423503326|\n",
      "|        Northridge| 410.9181617421861| 0.7009848961103857|\n",
      "|   Wilshire Center| 92.47700602600698| 0.8269584522676816|\n",
      "|    Jefferson Park| 195.7456647398844| 0.6410930110352075|\n",
      "|    Vermont Square|213.92902767920512| 0.7804116394606103|\n",
      "|Cloverdale/Cochran| 249.4237457240593| 0.6216505131128849|\n",
      "|   Adams-Normandie|160.62637082376943| 0.7148686559551135|\n",
      "+------------------+------------------+-------------------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import sum, count, col\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Σύνδεση Εισοδήματος / Περιοχών\n",
    "income_per_block = blocks_data  \\\n",
    "                        .hint(\"SHUFFLE_REPLICATE_NL\") \\\n",
    "                        .join(income_data, blocks_data[\"ZCTA10\"] == income_data[\"Zip Code\"]) \\\n",
    "                        .groupBy(\"COMM\") \\\n",
    "                        .agg( \\\n",
    "                            sum(\"POP_2010\").alias(\"Population\"), \\\n",
    "                            sum(\"Estimated Median Income\").alias(\"Total Income\") \\\n",
    "                        )\n",
    "\n",
    "# Σύνδεση Εγκλημάτων / Περιοχών με βάση το geometry, δηλαδή\n",
    "# το POINT του εγκλήματος βρίσκεται εντός του POLYGON της περιοχής\n",
    "crimes_per_block = crime_data \\\n",
    "                        .hint(\"SHUFFLE_REPLICATE_NL\") \\\n",
    "                        .join(blocks_data, ST_Within(crime_data[\"geom\"], blocks_data[\"geometry\"]), \"inner\") \\\n",
    "                        .groupBy(\"COMM\") \\\n",
    "                        .agg(count(\"*\").alias(\"Total Crimes\"))\n",
    "\n",
    "# Aναλογία συνολικού αριθμού εγκλημάτων ανά άτομο\n",
    "result = income_per_block \\\n",
    "                .hint(\"SHUFFLE_REPLICATE_NL\") \\\n",
    "                .join(crimes_per_block, on=[\"COMM\"]) \\\n",
    "                .withColumn(\"Income per Person\", col(\"Total Income\") / col(\"Population\")) \\\n",
    "                .withColumn(\"Crimes per Person\", col(\"Total Crimes\") / col(\"Population\")) \\\n",
    "                .select(\"COMM\", \"Income per Person\", \"Crimes per Person\")\n",
    "\n",
    "result.show()\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 16.96 seconds"
     ]
    }
   ],
   "source": [
    "elapsed_time = end_time - start_time\n",
    "print(f\"Time taken: {elapsed_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan (33)\n",
      "+- Project (32)\n",
      "   +- CartesianProduct Inner (31)\n",
      "      :- HashAggregate (13)\n",
      "      :  +- Exchange (12)\n",
      "      :     +- HashAggregate (11)\n",
      "      :        +- Project (10)\n",
      "      :           +- CartesianProduct Inner (9)\n",
      "      :              :- Project (5)\n",
      "      :              :  +- Filter (4)\n",
      "      :              :     +- Generate (3)\n",
      "      :              :        +- Filter (2)\n",
      "      :              :           +- Scan geojson  (1)\n",
      "      :              +- Project (8)\n",
      "      :                 +- Filter (7)\n",
      "      :                    +- Scan csv  (6)\n",
      "      +- HashAggregate (30)\n",
      "         +- Exchange (29)\n",
      "            +- HashAggregate (28)\n",
      "               +- Project (27)\n",
      "                  +- RangeJoin (26)\n",
      "                     :- Union (20)\n",
      "                     :  :- Project (16)\n",
      "                     :  :  +- Filter (15)\n",
      "                     :  :     +- Scan csv  (14)\n",
      "                     :  +- Project (19)\n",
      "                     :     +- Filter (18)\n",
      "                     :        +- Scan csv  (17)\n",
      "                     +- Project (25)\n",
      "                        +- Filter (24)\n",
      "                           +- Generate (23)\n",
      "                              +- Filter (22)\n",
      "                                 +- Scan geojson  (21)\n",
      "\n",
      "\n",
      "(1) Scan geojson \n",
      "Output [1]: [features#239]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/2010_Census_Blocks.geojson]\n",
      "PushedFilters: [IsNotNull(features)]\n",
      "ReadSchema: struct<features:array<struct<geometry:binary,properties:struct<BG10:string,BG10FIP10:string,BG12:string,CB10:string,CEN_FIP13:string,CITY:string,CITYCOM:string,COMM:string,CT10:string,CT12:string,CTCB10:string,HD_2012:bigint,HD_NAME:string,HOUSING10:bigint,LA_FIP10:string,OBJECTID:bigint,POP_2010:bigint,PUMA10:string,SPA_2012:bigint,SPA_NAME:string,SUP_DIST:string,SUP_LABEL:string,ShapeSTArea:double,ShapeSTLength:double,ZCTA10:string>,type:string>>>\n",
      "\n",
      "(2) Filter\n",
      "Input [1]: [features#239]\n",
      "Condition : ((size(features#239, true) > 0) AND isnotnull(features#239))\n",
      "\n",
      "(3) Generate\n",
      "Input [1]: [features#239]\n",
      "Arguments: explode(features#239), false, [features#247]\n",
      "\n",
      "(4) Filter\n",
      "Input [1]: [features#247]\n",
      "Condition : (((isnotnull(features#247.properties.POP_2010) AND isnotnull(features#247.properties.CITY)) AND ((isnotnull(features#247.properties.COMM) AND (features#247.properties.POP_2010 > 0)) AND (features#247.properties.CITY = Los Angeles))) AND isnotnull(features#247.properties.ZCTA10))\n",
      "\n",
      "(5) Project\n",
      "Output [3]: [features#247.properties.COMM AS COMM#263, features#247.properties.ZCTA10 AS ZCTA10#280, features#247.properties.POP_2010 AS POP_2010#272L]\n",
      "Input [1]: [features#247]\n",
      "\n",
      "(6) Scan csv \n",
      "Output [2]: [Zip Code#24, Estimated Median Income#26]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/LA_income_2015.csv]\n",
      "PushedFilters: [IsNotNull(Zip Code)]\n",
      "ReadSchema: struct<Zip Code:string,Estimated Median Income:string>\n",
      "\n",
      "(7) Filter\n",
      "Input [2]: [Zip Code#24, Estimated Median Income#26]\n",
      "Condition : isnotnull(Zip Code#24)\n",
      "\n",
      "(8) Project\n",
      "Output [2]: [Zip Code#24, cast(regexp_replace(Estimated Median Income#26, [$,], , 1) as float) AS Estimated Median Income#30]\n",
      "Input [2]: [Zip Code#24, Estimated Median Income#26]\n",
      "\n",
      "(9) CartesianProduct\n",
      "Join type: Inner\n",
      "Join condition: (ZCTA10#280 = Zip Code#24)\n",
      "\n",
      "(10) Project\n",
      "Output [3]: [COMM#263, POP_2010#272L, Estimated Median Income#30]\n",
      "Input [5]: [COMM#263, ZCTA10#280, POP_2010#272L, Zip Code#24, Estimated Median Income#30]\n",
      "\n",
      "(11) HashAggregate\n",
      "Input [3]: [COMM#263, POP_2010#272L, Estimated Median Income#30]\n",
      "Keys [1]: [COMM#263]\n",
      "Functions [2]: [partial_sum(POP_2010#272L), partial_sum(Estimated Median Income#30)]\n",
      "Aggregate Attributes [2]: [sum#1009L, sum#1011]\n",
      "Results [3]: [COMM#263, sum#1010L, sum#1012]\n",
      "\n",
      "(12) Exchange\n",
      "Input [3]: [COMM#263, sum#1010L, sum#1012]\n",
      "Arguments: hashpartitioning(COMM#263, 1000), ENSURE_REQUIREMENTS, [plan_id=3394]\n",
      "\n",
      "(13) HashAggregate\n",
      "Input [3]: [COMM#263, sum#1010L, sum#1012]\n",
      "Keys [1]: [COMM#263]\n",
      "Functions [2]: [sum(POP_2010#272L), sum(Estimated Median Income#30)]\n",
      "Aggregate Attributes [2]: [sum(POP_2010#272L)#919L, sum(Estimated Median Income#30)#921]\n",
      "Results [3]: [COMM#263, sum(POP_2010#272L)#919L AS Population#920L, sum(Estimated Median Income#30)#921 AS Total Income#922]\n",
      "\n",
      "(14) Scan csv \n",
      "Output [2]: [LAT#74, LON#75]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_Data_from_2010_to_2019_20241101.csv]\n",
      "ReadSchema: struct<LAT:double,LON:double>\n",
      "\n",
      "(15) Filter\n",
      "Input [2]: [LAT#74, LON#75]\n",
      "Condition : NOT ( **org.apache.spark.sql.sedona_sql.expressions.ST_Point**   = 0x120000000100000000000000000000000000000000000000)\n",
      "\n",
      "(16) Project\n",
      "Output [1]: [ **org.apache.spark.sql.sedona_sql.expressions.ST_Point**   AS geom#188]\n",
      "Input [2]: [LAT#74, LON#75]\n",
      "\n",
      "(17) Scan csv \n",
      "Output [2]: [LAT#130, LON#131]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_Data_from_2020_to_Present_20241101.csv]\n",
      "ReadSchema: struct<LAT:double,LON:double>\n",
      "\n",
      "(18) Filter\n",
      "Input [2]: [LAT#130, LON#131]\n",
      "Condition : NOT ( **org.apache.spark.sql.sedona_sql.expressions.ST_Point**   = 0x120000000100000000000000000000000000000000000000)\n",
      "\n",
      "(19) Project\n",
      "Output [1]: [ **org.apache.spark.sql.sedona_sql.expressions.ST_Point**   AS geom#1046]\n",
      "Input [2]: [LAT#130, LON#131]\n",
      "\n",
      "(20) Union\n",
      "\n",
      "(21) Scan geojson \n",
      "Output [1]: [features#949]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/2010_Census_Blocks.geojson]\n",
      "PushedFilters: [IsNotNull(features)]\n",
      "ReadSchema: struct<features:array<struct<geometry:binary,properties:struct<BG10:string,BG10FIP10:string,BG12:string,CB10:string,CEN_FIP13:string,CITY:string,CITYCOM:string,COMM:string,CT10:string,CT12:string,CTCB10:string,HD_2012:bigint,HD_NAME:string,HOUSING10:bigint,LA_FIP10:string,OBJECTID:bigint,POP_2010:bigint,PUMA10:string,SPA_2012:bigint,SPA_NAME:string,SUP_DIST:string,SUP_LABEL:string,ShapeSTArea:double,ShapeSTLength:double,ZCTA10:string>,type:string>>>\n",
      "\n",
      "(22) Filter\n",
      "Input [1]: [features#949]\n",
      "Condition : ((size(features#949, true) > 0) AND isnotnull(features#949))\n",
      "\n",
      "(23) Generate\n",
      "Input [1]: [features#949]\n",
      "Arguments: explode(features#949), false, [features#247]\n",
      "\n",
      "(24) Filter\n",
      "Input [1]: [features#247]\n",
      "Condition : (((((isnotnull(features#247.properties.POP_2010) AND isnotnull(features#247.properties.CITY)) AND isnotnull(features#247.properties.COMM)) AND (features#247.properties.POP_2010 > 0)) AND (features#247.properties.CITY = Los Angeles)) AND isnotnull(features#247.geometry))\n",
      "\n",
      "(25) Project\n",
      "Output [2]: [features#247.properties.COMM AS COMM#959, features#247.geometry AS geometry#250]\n",
      "Input [1]: [features#247]\n",
      "\n",
      "(26) RangeJoin\n",
      "Arguments: geom#188: geometry, geometry#250: geometry, WITHIN\n",
      "\n",
      "(27) Project\n",
      "Output [1]: [COMM#959]\n",
      "Input [3]: [geom#188, COMM#959, geometry#250]\n",
      "\n",
      "(28) HashAggregate\n",
      "Input [1]: [COMM#959]\n",
      "Keys [1]: [COMM#959]\n",
      "Functions [1]: [partial_count(1)]\n",
      "Aggregate Attributes [1]: [count#1013L]\n",
      "Results [2]: [COMM#959, count#1014L]\n",
      "\n",
      "(29) Exchange\n",
      "Input [2]: [COMM#959, count#1014L]\n",
      "Arguments: hashpartitioning(COMM#959, 1000), ENSURE_REQUIREMENTS, [plan_id=3462]\n",
      "\n",
      "(30) HashAggregate\n",
      "Input [2]: [COMM#959, count#1014L]\n",
      "Keys [1]: [COMM#959]\n",
      "Functions [1]: [count(1)]\n",
      "Aggregate Attributes [1]: [count(1)#944L]\n",
      "Results [2]: [COMM#959, count(1)#944L AS Total Crimes#945L]\n",
      "\n",
      "(31) CartesianProduct\n",
      "Join type: Inner\n",
      "Join condition: (COMM#263 = COMM#959)\n",
      "\n",
      "(32) Project\n",
      "Output [3]: [COMM#263, (Total Income#922 / cast(Population#920L as double)) AS Income per Person#982, (cast(Total Crimes#945L as double) / cast(Population#920L as double)) AS Crimes per Person#988]\n",
      "Input [5]: [COMM#263, Population#920L, Total Income#922, COMM#959, Total Crimes#945L]\n",
      "\n",
      "(33) AdaptiveSparkPlan\n",
      "Output [3]: [COMM#263, Income per Person#982, Crimes per Person#988]\n",
      "Arguments: isFinalPlan=false"
     ]
    }
   ],
   "source": [
    "result.explain(mode=\"formatted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Συμπεράσματα\n",
    "\n",
    "Η στρατηγική join που πετυχαίνει την καλύτερη επίδοση είναι η **SHUFFLE REPLICATE NL** (*Shuffle Replicate Nested Loop*) με χρόνο 16.96 δευτερόλεπτα.\n",
    "\n",
    "H στρατηγική **SHUFFLE HASH** πέτυχε λίγο καλύτερο χρόνο από τη **MERGE** με 29.44 και 40.95 δευτερόλεπτα αντίστοιχα.\n",
    "\n",
    "Τέλος, η στρατηγική **BROADCAST** δε μπόρεσε να εκτελεστεί, καθώς εξαντλεί τους πόρους μνήμης. Αυτό συμβαίνει επειδή προσπαθεί να στείλει ολόκληρο το μικρότερο dataset σε όλους τους εκτελεστές (*executors*), για να εκτελεστεί το join τοπικά χωρίς shuffling. Έτσι η μέθοδος αποτυγχάνει, καθώς το μέγεθος του dataset που πρόκειται να μεταδοθεί (broadcast) είναι πολύ μεγάλο για να χωρέσει στη μνήμη των εκτελεστών.\n",
    "\n",
    "Συνεπώς η καταλληλότερη στρατηγική για την περίπτωσή μας είναι η **SHUFFLE_REPLICATE_NL**."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Sparkmagic (PySpark)",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  },
  "name": "SparkLab - Introduction to RDDs and DataFrames"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
